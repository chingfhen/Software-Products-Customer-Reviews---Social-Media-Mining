{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d90106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e8df5",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8b45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\dataset.csv\")\n",
    "additional_features = pd.read_pickle(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\additional_features.pkl\")\n",
    "sentiment_lexicon_score = pd.read_pickle(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\sentiment_lexicon_score.pkl\")\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\summary_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    summary_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\review_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    review_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\keyword_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    keyword_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    tfidf = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf_names.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    tfidf_names = np.load(f, allow_pickle=True)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\topic_words.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    topic_words = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\word_scores.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    word_scores = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\topic_similarity_scores.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    topic_similarity_scores = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7625c5",
   "metadata": {},
   "source": [
    "### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bf2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['response'] = dataset.sentiment.map({\"POS\":1, \"NEU\":0,\"NEG\":-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea15b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embeddings_df = pd.DataFrame(summary_embeddings, columns = list(map(lambda value: f\"summary_embeddings_{value}\", range(summary_embeddings.shape[1]))))\n",
    "review_embeddings_df = pd.DataFrame(review_embeddings, columns = list(map(lambda value: f\"review_embeddings_{value}\", range(review_embeddings.shape[1]))))\n",
    "keyword_embeddings_df = pd.DataFrame(keyword_embeddings, columns = list(map(lambda value: f\"keyword_embeddings_{value}\", range(keyword_embeddings.shape[1]))))\n",
    "tfidf_df = pd.DataFrame(tfidf, columns = \"tfidf_\"+tfidf_names)\n",
    "tfidf_cols = [col for col in tfidf_df.columns if col[6:] in topic_words.flatten()]\n",
    "topic_similarity_scores_df = pd.DataFrame(topic_similarity_scores, columns = list(map(lambda value: f\"topic_similarity_{value}\", range(topic_similarity_scores.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a712f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([additional_features.merge(sentiment_lexicon_score, on = \"reviewId\"),summary_embeddings_df,review_embeddings_df,keyword_embeddings_df,tfidf_df[tfidf_cols],topic_similarity_scores_df], axis = 1)\n",
    "features = features.drop(\"reviewId\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644f9fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_uppercase_words</th>\n",
       "      <th>punc_!</th>\n",
       "      <th>punc_\"</th>\n",
       "      <th>punc_#</th>\n",
       "      <th>punc_$</th>\n",
       "      <th>punc_%</th>\n",
       "      <th>punc_&amp;</th>\n",
       "      <th>punc_'</th>\n",
       "      <th>punc_(</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_similarity_26</th>\n",
       "      <th>topic_similarity_27</th>\n",
       "      <th>topic_similarity_28</th>\n",
       "      <th>topic_similarity_29</th>\n",
       "      <th>topic_similarity_30</th>\n",
       "      <th>topic_similarity_31</th>\n",
       "      <th>topic_similarity_32</th>\n",
       "      <th>topic_similarity_33</th>\n",
       "      <th>topic_similarity_34</th>\n",
       "      <th>topic_similarity_35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076096</td>\n",
       "      <td>-0.016495</td>\n",
       "      <td>0.051254</td>\n",
       "      <td>0.181995</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.163936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>746</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017875</td>\n",
       "      <td>0.049456</td>\n",
       "      <td>-0.028948</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>-0.019422</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.136973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>-0.007581</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.155227</td>\n",
       "      <td>0.059554</td>\n",
       "      <td>-0.006792</td>\n",
       "      <td>0.146159</td>\n",
       "      <td>0.088288</td>\n",
       "      <td>0.081141</td>\n",
       "      <td>0.240325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071355</td>\n",
       "      <td>0.120201</td>\n",
       "      <td>0.084645</td>\n",
       "      <td>0.166351</td>\n",
       "      <td>0.134689</td>\n",
       "      <td>-0.010713</td>\n",
       "      <td>0.155522</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>0.104016</td>\n",
       "      <td>0.178283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>0.200227</td>\n",
       "      <td>0.095242</td>\n",
       "      <td>-0.011464</td>\n",
       "      <td>0.129631</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.198467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128085</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.154269</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>-0.035820</td>\n",
       "      <td>0.043859</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>0.107429</td>\n",
       "      <td>0.029032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>61</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187186</td>\n",
       "      <td>0.168873</td>\n",
       "      <td>0.128415</td>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>-0.116134</td>\n",
       "      <td>0.146911</td>\n",
       "      <td>0.232461</td>\n",
       "      <td>0.117452</td>\n",
       "      <td>0.118289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>135</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079596</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.148075</td>\n",
       "      <td>0.200458</td>\n",
       "      <td>0.158441</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.167102</td>\n",
       "      <td>0.061767</td>\n",
       "      <td>0.103545</td>\n",
       "      <td>0.222701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>144</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049273</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>0.299228</td>\n",
       "      <td>0.033641</td>\n",
       "      <td>0.111919</td>\n",
       "      <td>0.110183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144625</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.139739</td>\n",
       "      <td>-0.035107</td>\n",
       "      <td>0.231315</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.161697</td>\n",
       "      <td>0.125282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4440 rows Ã— 2223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  num_uppercase_words  punc_!  punc_\"  punc_#  punc_$  punc_%  \\\n",
       "0          1439                  231       0      17       0       1       0   \n",
       "1           746                  113       0       6       0       0       0   \n",
       "2           246                   37       0       2       0       0       0   \n",
       "3           235                   31       0       2       0       0       0   \n",
       "4           211                   41       0       0       0       0       0   \n",
       "...         ...                  ...     ...     ...     ...     ...     ...   \n",
       "4435          2                    0       0       0       0       0       0   \n",
       "4436         61                   14       0       0       0       0       0   \n",
       "4437        135                   12       2       0       0       0       0   \n",
       "4438        144                   24       0       0       0       0       0   \n",
       "4439        110                   12       0       2       0       0       0   \n",
       "\n",
       "      punc_&  punc_'  punc_(  ...  topic_similarity_26  topic_similarity_27  \\\n",
       "0          1      39      26  ...             0.076096            -0.016495   \n",
       "1          0       9      13  ...            -0.017875             0.049456   \n",
       "2          0       3       1  ...             0.008039            -0.007581   \n",
       "3          0       6       0  ...             0.071355             0.120201   \n",
       "4          0       7       2  ...             0.069261             0.046579   \n",
       "...      ...     ...     ...  ...                  ...                  ...   \n",
       "4435       0       0       0  ...             0.128085             0.094547   \n",
       "4436       0       0       0  ...             0.187186             0.168873   \n",
       "4437       0       2       0  ...             0.079596             0.038898   \n",
       "4438       0       2       1  ...             0.049273            -0.040922   \n",
       "4439       0       2       0  ...             0.144625             0.126106   \n",
       "\n",
       "      topic_similarity_28  topic_similarity_29  topic_similarity_30  \\\n",
       "0                0.051254             0.181995            -0.002860   \n",
       "1               -0.028948             0.110548             0.030363   \n",
       "2                0.026354             0.155227             0.059554   \n",
       "3                0.084645             0.166351             0.134689   \n",
       "4                0.070348             0.200227             0.095242   \n",
       "...                   ...                  ...                  ...   \n",
       "4435             0.154269             0.045453            -0.035820   \n",
       "4436             0.128415             0.137136             0.106234   \n",
       "4437             0.148075             0.200458             0.158441   \n",
       "4438             0.088658             0.046652             0.033721   \n",
       "4439             0.044610             0.111600             0.139739   \n",
       "\n",
       "      topic_similarity_31  topic_similarity_32  topic_similarity_33  \\\n",
       "0               -0.002951             0.037847            -0.042878   \n",
       "1                0.005043             0.063827            -0.019422   \n",
       "2               -0.006792             0.146159             0.088288   \n",
       "3               -0.010713             0.155522             0.083599   \n",
       "4               -0.011464             0.129631             0.016090   \n",
       "...                   ...                  ...                  ...   \n",
       "4435             0.043859             0.006198             0.112948   \n",
       "4436            -0.116134             0.146911             0.232461   \n",
       "4437             0.002689             0.167102             0.061767   \n",
       "4438             0.151388             0.299228             0.033641   \n",
       "4439            -0.035107             0.231315             0.041344   \n",
       "\n",
       "      topic_similarity_34  topic_similarity_35  \n",
       "0                0.012343             0.163936  \n",
       "1                0.048254             0.136973  \n",
       "2                0.081141             0.240325  \n",
       "3                0.104016             0.178283  \n",
       "4                0.093500             0.198467  \n",
       "...                   ...                  ...  \n",
       "4435             0.107429             0.029032  \n",
       "4436             0.117452             0.118289  \n",
       "4437             0.103545             0.222701  \n",
       "4438             0.111919             0.110183  \n",
       "4439             0.161697             0.125282  \n",
       "\n",
       "[4440 rows x 2223 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c84be",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7164bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db828bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cols = [col for col in features if \"tfidf\" not in col]\n",
    "# X_cols = ['sentiment_lexicon_score_summary',\n",
    "#  'sentiment_lexicon_score_review']\n",
    "# X_cols = [col for col in features if \"summary_embeddings\" in col]\n",
    "# X_cols = ['num_words', 'num_uppercase_words', 'punc_!', 'punc_\"', 'punc_#', 'punc_$', 'punc_%', 'punc_&', \"punc_'\", 'punc_(', 'punc_)', 'punc_*', 'punc_+', 'punc_,', 'punc_-', 'punc_.', 'punc_/', 'punc_:', 'punc_;', 'punc_<', 'punc_=', 'punc_>', 'punc_?', 'punc_@', 'punc_[', 'punc_\\\\', 'punc_]', 'punc_^', 'punc__', 'punc_`', 'punc_{', 'punc_|', 'punc_}', 'punc_~']\n",
    "# X_cols = [col for col in features if \"keyword_embeddings\" in col]\n",
    "# X_cols = [col for col in features if \"review_embeddings\" in col]\n",
    "# X_cols = [col for col in features if \"topic_similarity\" in col]\n",
    "# X_cols = tfidf_cols\n",
    "X = features\n",
    "y = dataset['response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62fd7a",
   "metadata": {},
   "source": [
    "### model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ea40cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\":1000,\n",
    "    'num_leaves': 163,\n",
    "    'bagging_fraction': 0.80,\n",
    "    'lambda_l1': 0.00019163693019842484,\n",
    "    'lambda_l2': 0.0027009967266884796,\n",
    "    'feature_fraction': 0.60,\n",
    "    'boosting': 'gbdt',\n",
    "    \"learning_rate\":0.01,\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"max_depth\":  -1,\n",
    "    \"bagging_freq\": 5 ,                  # resamples rows at every k-th iteration\n",
    "    \"force_col_wise\":  True  ,                 # reduce memory cost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b491abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cca03c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_feature_names = {'punc_!': 'punc_0', 'punc_\"': 'punc_1', 'punc_#': 'punc_2', 'punc_$': 'punc_3', 'punc_%': 'punc_4', 'punc_&': 'punc_5', \"punc_'\": 'punc_6', 'punc_(': 'punc_7', 'punc_)': 'punc_8', 'punc_*': 'punc_9', 'punc_+': 'punc_10', 'punc_,': 'punc_11', 'punc_-': 'punc_12', 'punc_.': 'punc_13', 'punc_/': 'punc_14', 'punc_:': 'punc_15', 'punc_;': 'punc_16', 'punc_<': 'punc_17', 'punc_=': 'punc_18', 'punc_>': 'punc_19', 'punc_?': 'punc_20', 'punc_@': 'punc_21', 'punc_[': 'punc_22', 'punc_\\\\': 'punc_23', 'punc_]': 'punc_24', 'punc_^': 'punc_25', 'punc__': 'punc_26', 'punc_`': 'punc_27', 'punc_{': 'punc_28', 'punc_|': 'punc_29', 'punc_}': 'punc_30', 'punc_~': 'punc_31'}\n",
    "X.rename(columns = punc_feature_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ec32ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00019163693019842484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019163693019842484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0027009967266884796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0027009967266884796\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[1]\tvalid_0's multi_logloss: 1.09454\n",
      "[2]\tvalid_0's multi_logloss: 1.08901\n",
      "[3]\tvalid_0's multi_logloss: 1.08361\n",
      "[4]\tvalid_0's multi_logloss: 1.07874\n",
      "[5]\tvalid_0's multi_logloss: 1.07319\n",
      "[6]\tvalid_0's multi_logloss: 1.06832\n",
      "[7]\tvalid_0's multi_logloss: 1.06338\n",
      "[8]\tvalid_0's multi_logloss: 1.05847\n",
      "[9]\tvalid_0's multi_logloss: 1.054\n",
      "[10]\tvalid_0's multi_logloss: 1.04939\n",
      "[11]\tvalid_0's multi_logloss: 1.04503\n",
      "[12]\tvalid_0's multi_logloss: 1.04025\n",
      "[13]\tvalid_0's multi_logloss: 1.03564\n",
      "[14]\tvalid_0's multi_logloss: 1.03151\n",
      "[15]\tvalid_0's multi_logloss: 1.02725\n",
      "[16]\tvalid_0's multi_logloss: 1.0231\n",
      "[17]\tvalid_0's multi_logloss: 1.01913\n",
      "[18]\tvalid_0's multi_logloss: 1.01524\n",
      "[19]\tvalid_0's multi_logloss: 1.01164\n",
      "[20]\tvalid_0's multi_logloss: 1.00764\n",
      "[21]\tvalid_0's multi_logloss: 1.00412\n",
      "[22]\tvalid_0's multi_logloss: 1.00007\n",
      "[23]\tvalid_0's multi_logloss: 0.996629\n",
      "[24]\tvalid_0's multi_logloss: 0.992542\n",
      "[25]\tvalid_0's multi_logloss: 0.988866\n",
      "[26]\tvalid_0's multi_logloss: 0.985485\n",
      "[27]\tvalid_0's multi_logloss: 0.982218\n",
      "[28]\tvalid_0's multi_logloss: 0.978679\n",
      "[29]\tvalid_0's multi_logloss: 0.975202\n",
      "[30]\tvalid_0's multi_logloss: 0.971918\n",
      "[31]\tvalid_0's multi_logloss: 0.968509\n",
      "[32]\tvalid_0's multi_logloss: 0.96535\n",
      "[33]\tvalid_0's multi_logloss: 0.962132\n",
      "[34]\tvalid_0's multi_logloss: 0.958935\n",
      "[35]\tvalid_0's multi_logloss: 0.955867\n",
      "[36]\tvalid_0's multi_logloss: 0.952742\n",
      "[37]\tvalid_0's multi_logloss: 0.949509\n",
      "[38]\tvalid_0's multi_logloss: 0.946128\n",
      "[39]\tvalid_0's multi_logloss: 0.942965\n",
      "[40]\tvalid_0's multi_logloss: 0.940166\n",
      "[41]\tvalid_0's multi_logloss: 0.937373\n",
      "[42]\tvalid_0's multi_logloss: 0.934204\n",
      "[43]\tvalid_0's multi_logloss: 0.931273\n",
      "[44]\tvalid_0's multi_logloss: 0.928597\n",
      "[45]\tvalid_0's multi_logloss: 0.925856\n",
      "[46]\tvalid_0's multi_logloss: 0.922736\n",
      "[47]\tvalid_0's multi_logloss: 0.919864\n",
      "[48]\tvalid_0's multi_logloss: 0.917391\n",
      "[49]\tvalid_0's multi_logloss: 0.914851\n",
      "[50]\tvalid_0's multi_logloss: 0.912224\n",
      "[51]\tvalid_0's multi_logloss: 0.909384\n",
      "[52]\tvalid_0's multi_logloss: 0.9071\n",
      "[53]\tvalid_0's multi_logloss: 0.904333\n",
      "[54]\tvalid_0's multi_logloss: 0.901806\n",
      "[55]\tvalid_0's multi_logloss: 0.898937\n",
      "[56]\tvalid_0's multi_logloss: 0.89638\n",
      "[57]\tvalid_0's multi_logloss: 0.893872\n",
      "[58]\tvalid_0's multi_logloss: 0.891522\n",
      "[59]\tvalid_0's multi_logloss: 0.889228\n",
      "[60]\tvalid_0's multi_logloss: 0.887137\n",
      "[61]\tvalid_0's multi_logloss: 0.885017\n",
      "[62]\tvalid_0's multi_logloss: 0.882601\n",
      "[63]\tvalid_0's multi_logloss: 0.880374\n",
      "[64]\tvalid_0's multi_logloss: 0.878016\n",
      "[65]\tvalid_0's multi_logloss: 0.875665\n",
      "[66]\tvalid_0's multi_logloss: 0.873568\n",
      "[67]\tvalid_0's multi_logloss: 0.871519\n",
      "[68]\tvalid_0's multi_logloss: 0.869163\n",
      "[69]\tvalid_0's multi_logloss: 0.867309\n",
      "[70]\tvalid_0's multi_logloss: 0.865137\n",
      "[71]\tvalid_0's multi_logloss: 0.863082\n",
      "[72]\tvalid_0's multi_logloss: 0.860889\n",
      "[73]\tvalid_0's multi_logloss: 0.858865\n",
      "[74]\tvalid_0's multi_logloss: 0.856922\n",
      "[75]\tvalid_0's multi_logloss: 0.854694\n",
      "[76]\tvalid_0's multi_logloss: 0.852781\n",
      "[77]\tvalid_0's multi_logloss: 0.85085\n",
      "[78]\tvalid_0's multi_logloss: 0.848695\n",
      "[79]\tvalid_0's multi_logloss: 0.846682\n",
      "[80]\tvalid_0's multi_logloss: 0.844918\n",
      "[81]\tvalid_0's multi_logloss: 0.842948\n",
      "[82]\tvalid_0's multi_logloss: 0.840867\n",
      "[83]\tvalid_0's multi_logloss: 0.838907\n",
      "[84]\tvalid_0's multi_logloss: 0.837333\n",
      "[85]\tvalid_0's multi_logloss: 0.83547\n",
      "[86]\tvalid_0's multi_logloss: 0.833604\n",
      "[87]\tvalid_0's multi_logloss: 0.831892\n",
      "[88]\tvalid_0's multi_logloss: 0.830198\n",
      "[89]\tvalid_0's multi_logloss: 0.828591\n",
      "[90]\tvalid_0's multi_logloss: 0.827204\n",
      "[91]\tvalid_0's multi_logloss: 0.825545\n",
      "[92]\tvalid_0's multi_logloss: 0.823808\n",
      "[93]\tvalid_0's multi_logloss: 0.822368\n",
      "[94]\tvalid_0's multi_logloss: 0.82063\n",
      "[95]\tvalid_0's multi_logloss: 0.818837\n",
      "[96]\tvalid_0's multi_logloss: 0.817343\n",
      "[97]\tvalid_0's multi_logloss: 0.816127\n",
      "[98]\tvalid_0's multi_logloss: 0.814469\n",
      "[99]\tvalid_0's multi_logloss: 0.813055\n",
      "[100]\tvalid_0's multi_logloss: 0.811598\n",
      "[101]\tvalid_0's multi_logloss: 0.810103\n",
      "[102]\tvalid_0's multi_logloss: 0.808714\n",
      "[103]\tvalid_0's multi_logloss: 0.807281\n",
      "[104]\tvalid_0's multi_logloss: 0.805671\n",
      "[105]\tvalid_0's multi_logloss: 0.804158\n",
      "[106]\tvalid_0's multi_logloss: 0.802784\n",
      "[107]\tvalid_0's multi_logloss: 0.801509\n",
      "[108]\tvalid_0's multi_logloss: 0.800086\n",
      "[109]\tvalid_0's multi_logloss: 0.79882\n",
      "[110]\tvalid_0's multi_logloss: 0.797441\n",
      "[111]\tvalid_0's multi_logloss: 0.795941\n",
      "[112]\tvalid_0's multi_logloss: 0.794611\n",
      "[113]\tvalid_0's multi_logloss: 0.793379\n",
      "[114]\tvalid_0's multi_logloss: 0.79182\n",
      "[115]\tvalid_0's multi_logloss: 0.790724\n",
      "[116]\tvalid_0's multi_logloss: 0.78935\n",
      "[117]\tvalid_0's multi_logloss: 0.787862\n",
      "[118]\tvalid_0's multi_logloss: 0.786559\n",
      "[119]\tvalid_0's multi_logloss: 0.785349\n",
      "[120]\tvalid_0's multi_logloss: 0.784202\n",
      "[121]\tvalid_0's multi_logloss: 0.783012\n",
      "[122]\tvalid_0's multi_logloss: 0.78203\n",
      "[123]\tvalid_0's multi_logloss: 0.780861\n",
      "[124]\tvalid_0's multi_logloss: 0.779397\n",
      "[125]\tvalid_0's multi_logloss: 0.77795\n",
      "[126]\tvalid_0's multi_logloss: 0.776876\n",
      "[127]\tvalid_0's multi_logloss: 0.775516\n",
      "[128]\tvalid_0's multi_logloss: 0.774206\n",
      "[129]\tvalid_0's multi_logloss: 0.773075\n",
      "[130]\tvalid_0's multi_logloss: 0.771958\n",
      "[131]\tvalid_0's multi_logloss: 0.77109\n",
      "[132]\tvalid_0's multi_logloss: 0.769872\n",
      "[133]\tvalid_0's multi_logloss: 0.768783\n",
      "[134]\tvalid_0's multi_logloss: 0.767575\n",
      "[135]\tvalid_0's multi_logloss: 0.766309\n",
      "[136]\tvalid_0's multi_logloss: 0.765357\n",
      "[137]\tvalid_0's multi_logloss: 0.764348\n",
      "[138]\tvalid_0's multi_logloss: 0.763199\n",
      "[139]\tvalid_0's multi_logloss: 0.762263\n",
      "[140]\tvalid_0's multi_logloss: 0.761211\n",
      "[141]\tvalid_0's multi_logloss: 0.760249\n",
      "[142]\tvalid_0's multi_logloss: 0.759084\n",
      "[143]\tvalid_0's multi_logloss: 0.757855\n",
      "[144]\tvalid_0's multi_logloss: 0.756841\n",
      "[145]\tvalid_0's multi_logloss: 0.75552\n",
      "[146]\tvalid_0's multi_logloss: 0.754384\n",
      "[147]\tvalid_0's multi_logloss: 0.753381\n",
      "[148]\tvalid_0's multi_logloss: 0.752349\n",
      "[149]\tvalid_0's multi_logloss: 0.751293\n",
      "[150]\tvalid_0's multi_logloss: 0.750092\n",
      "[151]\tvalid_0's multi_logloss: 0.749088\n",
      "[152]\tvalid_0's multi_logloss: 0.74801\n",
      "[153]\tvalid_0's multi_logloss: 0.747127\n",
      "[154]\tvalid_0's multi_logloss: 0.746179\n",
      "[155]\tvalid_0's multi_logloss: 0.745158\n",
      "[156]\tvalid_0's multi_logloss: 0.744295\n",
      "[157]\tvalid_0's multi_logloss: 0.743425\n",
      "[158]\tvalid_0's multi_logloss: 0.74267\n",
      "[159]\tvalid_0's multi_logloss: 0.741763\n",
      "[160]\tvalid_0's multi_logloss: 0.740664\n",
      "[161]\tvalid_0's multi_logloss: 0.739867\n",
      "[162]\tvalid_0's multi_logloss: 0.738943\n",
      "[163]\tvalid_0's multi_logloss: 0.738117\n",
      "[164]\tvalid_0's multi_logloss: 0.737253\n",
      "[165]\tvalid_0's multi_logloss: 0.736275\n",
      "[166]\tvalid_0's multi_logloss: 0.735351\n",
      "[167]\tvalid_0's multi_logloss: 0.734469\n",
      "[168]\tvalid_0's multi_logloss: 0.733717\n",
      "[169]\tvalid_0's multi_logloss: 0.73281\n",
      "[170]\tvalid_0's multi_logloss: 0.732079\n",
      "[171]\tvalid_0's multi_logloss: 0.731208\n",
      "[172]\tvalid_0's multi_logloss: 0.730441\n",
      "[173]\tvalid_0's multi_logloss: 0.729711\n",
      "[174]\tvalid_0's multi_logloss: 0.728993\n",
      "[175]\tvalid_0's multi_logloss: 0.727976\n",
      "[176]\tvalid_0's multi_logloss: 0.727263\n",
      "[177]\tvalid_0's multi_logloss: 0.726757\n",
      "[178]\tvalid_0's multi_logloss: 0.725948\n",
      "[179]\tvalid_0's multi_logloss: 0.725224\n",
      "[180]\tvalid_0's multi_logloss: 0.724566\n",
      "[181]\tvalid_0's multi_logloss: 0.723865\n",
      "[182]\tvalid_0's multi_logloss: 0.72325\n",
      "[183]\tvalid_0's multi_logloss: 0.722736\n",
      "[184]\tvalid_0's multi_logloss: 0.721936\n",
      "[185]\tvalid_0's multi_logloss: 0.721373\n",
      "[186]\tvalid_0's multi_logloss: 0.720475\n",
      "[187]\tvalid_0's multi_logloss: 0.719689\n",
      "[188]\tvalid_0's multi_logloss: 0.718895\n",
      "[189]\tvalid_0's multi_logloss: 0.718061\n",
      "[190]\tvalid_0's multi_logloss: 0.717324\n",
      "[191]\tvalid_0's multi_logloss: 0.716487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\tvalid_0's multi_logloss: 0.715742\n",
      "[193]\tvalid_0's multi_logloss: 0.71525\n",
      "[194]\tvalid_0's multi_logloss: 0.714494\n",
      "[195]\tvalid_0's multi_logloss: 0.713862\n",
      "[196]\tvalid_0's multi_logloss: 0.713321\n",
      "[197]\tvalid_0's multi_logloss: 0.712668\n",
      "[198]\tvalid_0's multi_logloss: 0.711975\n",
      "[199]\tvalid_0's multi_logloss: 0.711252\n",
      "[200]\tvalid_0's multi_logloss: 0.710428\n",
      "[201]\tvalid_0's multi_logloss: 0.709877\n",
      "[202]\tvalid_0's multi_logloss: 0.709137\n",
      "[203]\tvalid_0's multi_logloss: 0.708508\n",
      "[204]\tvalid_0's multi_logloss: 0.707817\n",
      "[205]\tvalid_0's multi_logloss: 0.707176\n",
      "[206]\tvalid_0's multi_logloss: 0.706535\n",
      "[207]\tvalid_0's multi_logloss: 0.705741\n",
      "[208]\tvalid_0's multi_logloss: 0.704987\n",
      "[209]\tvalid_0's multi_logloss: 0.704524\n",
      "[210]\tvalid_0's multi_logloss: 0.703722\n",
      "[211]\tvalid_0's multi_logloss: 0.703078\n",
      "[212]\tvalid_0's multi_logloss: 0.702435\n",
      "[213]\tvalid_0's multi_logloss: 0.702089\n",
      "[214]\tvalid_0's multi_logloss: 0.701392\n",
      "[215]\tvalid_0's multi_logloss: 0.700649\n",
      "[216]\tvalid_0's multi_logloss: 0.700152\n",
      "[217]\tvalid_0's multi_logloss: 0.699576\n",
      "[218]\tvalid_0's multi_logloss: 0.698972\n",
      "[219]\tvalid_0's multi_logloss: 0.698474\n",
      "[220]\tvalid_0's multi_logloss: 0.697847\n",
      "[221]\tvalid_0's multi_logloss: 0.697287\n",
      "[222]\tvalid_0's multi_logloss: 0.696782\n",
      "[223]\tvalid_0's multi_logloss: 0.696319\n",
      "[224]\tvalid_0's multi_logloss: 0.695834\n",
      "[225]\tvalid_0's multi_logloss: 0.695375\n",
      "[226]\tvalid_0's multi_logloss: 0.694942\n",
      "[227]\tvalid_0's multi_logloss: 0.694384\n",
      "[228]\tvalid_0's multi_logloss: 0.693697\n",
      "[229]\tvalid_0's multi_logloss: 0.693014\n",
      "[230]\tvalid_0's multi_logloss: 0.692471\n",
      "[231]\tvalid_0's multi_logloss: 0.691999\n",
      "[232]\tvalid_0's multi_logloss: 0.691596\n",
      "[233]\tvalid_0's multi_logloss: 0.690955\n",
      "[234]\tvalid_0's multi_logloss: 0.690331\n",
      "[235]\tvalid_0's multi_logloss: 0.689791\n",
      "[236]\tvalid_0's multi_logloss: 0.689141\n",
      "[237]\tvalid_0's multi_logloss: 0.688628\n",
      "[238]\tvalid_0's multi_logloss: 0.688124\n",
      "[239]\tvalid_0's multi_logloss: 0.687572\n",
      "[240]\tvalid_0's multi_logloss: 0.686816\n",
      "[241]\tvalid_0's multi_logloss: 0.686193\n",
      "[242]\tvalid_0's multi_logloss: 0.685783\n",
      "[243]\tvalid_0's multi_logloss: 0.685391\n",
      "[244]\tvalid_0's multi_logloss: 0.684788\n",
      "[245]\tvalid_0's multi_logloss: 0.684249\n",
      "[246]\tvalid_0's multi_logloss: 0.683699\n",
      "[247]\tvalid_0's multi_logloss: 0.683251\n",
      "[248]\tvalid_0's multi_logloss: 0.682694\n",
      "[249]\tvalid_0's multi_logloss: 0.682272\n",
      "[250]\tvalid_0's multi_logloss: 0.681829\n",
      "[251]\tvalid_0's multi_logloss: 0.681366\n",
      "[252]\tvalid_0's multi_logloss: 0.680934\n",
      "[253]\tvalid_0's multi_logloss: 0.680514\n",
      "[254]\tvalid_0's multi_logloss: 0.680153\n",
      "[255]\tvalid_0's multi_logloss: 0.679605\n",
      "[256]\tvalid_0's multi_logloss: 0.679244\n",
      "[257]\tvalid_0's multi_logloss: 0.678938\n",
      "[258]\tvalid_0's multi_logloss: 0.678397\n",
      "[259]\tvalid_0's multi_logloss: 0.677966\n",
      "[260]\tvalid_0's multi_logloss: 0.677553\n",
      "[261]\tvalid_0's multi_logloss: 0.676987\n",
      "[262]\tvalid_0's multi_logloss: 0.676543\n",
      "[263]\tvalid_0's multi_logloss: 0.676014\n",
      "[264]\tvalid_0's multi_logloss: 0.675477\n",
      "[265]\tvalid_0's multi_logloss: 0.675059\n",
      "[266]\tvalid_0's multi_logloss: 0.674775\n",
      "[267]\tvalid_0's multi_logloss: 0.674459\n",
      "[268]\tvalid_0's multi_logloss: 0.674173\n",
      "[269]\tvalid_0's multi_logloss: 0.673838\n",
      "[270]\tvalid_0's multi_logloss: 0.673465\n",
      "[271]\tvalid_0's multi_logloss: 0.673021\n",
      "[272]\tvalid_0's multi_logloss: 0.672826\n",
      "[273]\tvalid_0's multi_logloss: 0.672357\n",
      "[274]\tvalid_0's multi_logloss: 0.671921\n",
      "[275]\tvalid_0's multi_logloss: 0.671366\n",
      "[276]\tvalid_0's multi_logloss: 0.670939\n",
      "[277]\tvalid_0's multi_logloss: 0.670694\n",
      "[278]\tvalid_0's multi_logloss: 0.670239\n",
      "[279]\tvalid_0's multi_logloss: 0.669786\n",
      "[280]\tvalid_0's multi_logloss: 0.669295\n",
      "[281]\tvalid_0's multi_logloss: 0.668947\n",
      "[282]\tvalid_0's multi_logloss: 0.668454\n",
      "[283]\tvalid_0's multi_logloss: 0.668066\n",
      "[284]\tvalid_0's multi_logloss: 0.667721\n",
      "[285]\tvalid_0's multi_logloss: 0.667576\n",
      "[286]\tvalid_0's multi_logloss: 0.667181\n",
      "[287]\tvalid_0's multi_logloss: 0.666856\n",
      "[288]\tvalid_0's multi_logloss: 0.666466\n",
      "[289]\tvalid_0's multi_logloss: 0.666074\n",
      "[290]\tvalid_0's multi_logloss: 0.665576\n",
      "[291]\tvalid_0's multi_logloss: 0.66524\n",
      "[292]\tvalid_0's multi_logloss: 0.664968\n",
      "[293]\tvalid_0's multi_logloss: 0.66458\n",
      "[294]\tvalid_0's multi_logloss: 0.664134\n",
      "[295]\tvalid_0's multi_logloss: 0.663857\n",
      "[296]\tvalid_0's multi_logloss: 0.663691\n",
      "[297]\tvalid_0's multi_logloss: 0.66342\n",
      "[298]\tvalid_0's multi_logloss: 0.66307\n",
      "[299]\tvalid_0's multi_logloss: 0.662828\n",
      "[300]\tvalid_0's multi_logloss: 0.662555\n",
      "[301]\tvalid_0's multi_logloss: 0.662213\n",
      "[302]\tvalid_0's multi_logloss: 0.661972\n",
      "[303]\tvalid_0's multi_logloss: 0.661621\n",
      "[304]\tvalid_0's multi_logloss: 0.6612\n",
      "[305]\tvalid_0's multi_logloss: 0.660769\n",
      "[306]\tvalid_0's multi_logloss: 0.660439\n",
      "[307]\tvalid_0's multi_logloss: 0.66023\n",
      "[308]\tvalid_0's multi_logloss: 0.660001\n",
      "[309]\tvalid_0's multi_logloss: 0.659623\n",
      "[310]\tvalid_0's multi_logloss: 0.659397\n",
      "[311]\tvalid_0's multi_logloss: 0.659147\n",
      "[312]\tvalid_0's multi_logloss: 0.658782\n",
      "[313]\tvalid_0's multi_logloss: 0.658558\n",
      "[314]\tvalid_0's multi_logloss: 0.658132\n",
      "[315]\tvalid_0's multi_logloss: 0.657775\n",
      "[316]\tvalid_0's multi_logloss: 0.657434\n",
      "[317]\tvalid_0's multi_logloss: 0.657106\n",
      "[318]\tvalid_0's multi_logloss: 0.656861\n",
      "[319]\tvalid_0's multi_logloss: 0.656567\n",
      "[320]\tvalid_0's multi_logloss: 0.656383\n",
      "[321]\tvalid_0's multi_logloss: 0.655958\n",
      "[322]\tvalid_0's multi_logloss: 0.655732\n",
      "[323]\tvalid_0's multi_logloss: 0.655501\n",
      "[324]\tvalid_0's multi_logloss: 0.655231\n",
      "[325]\tvalid_0's multi_logloss: 0.654803\n",
      "[326]\tvalid_0's multi_logloss: 0.654648\n",
      "[327]\tvalid_0's multi_logloss: 0.654541\n",
      "[328]\tvalid_0's multi_logloss: 0.65442\n",
      "[329]\tvalid_0's multi_logloss: 0.654082\n",
      "[330]\tvalid_0's multi_logloss: 0.653896\n",
      "[331]\tvalid_0's multi_logloss: 0.653493\n",
      "[332]\tvalid_0's multi_logloss: 0.653061\n",
      "[333]\tvalid_0's multi_logloss: 0.652738\n",
      "[334]\tvalid_0's multi_logloss: 0.652372\n",
      "[335]\tvalid_0's multi_logloss: 0.652085\n",
      "[336]\tvalid_0's multi_logloss: 0.651689\n",
      "[337]\tvalid_0's multi_logloss: 0.651328\n",
      "[338]\tvalid_0's multi_logloss: 0.651024\n",
      "[339]\tvalid_0's multi_logloss: 0.650949\n",
      "[340]\tvalid_0's multi_logloss: 0.650737\n",
      "[341]\tvalid_0's multi_logloss: 0.650563\n",
      "[342]\tvalid_0's multi_logloss: 0.650373\n",
      "[343]\tvalid_0's multi_logloss: 0.650256\n",
      "[344]\tvalid_0's multi_logloss: 0.649971\n",
      "[345]\tvalid_0's multi_logloss: 0.649881\n",
      "[346]\tvalid_0's multi_logloss: 0.649593\n",
      "[347]\tvalid_0's multi_logloss: 0.649291\n",
      "[348]\tvalid_0's multi_logloss: 0.649153\n",
      "[349]\tvalid_0's multi_logloss: 0.64893\n",
      "[350]\tvalid_0's multi_logloss: 0.648659\n",
      "[351]\tvalid_0's multi_logloss: 0.648381\n",
      "[352]\tvalid_0's multi_logloss: 0.648158\n",
      "[353]\tvalid_0's multi_logloss: 0.648033\n",
      "[354]\tvalid_0's multi_logloss: 0.647828\n",
      "[355]\tvalid_0's multi_logloss: 0.647895\n",
      "[356]\tvalid_0's multi_logloss: 0.647816\n",
      "[357]\tvalid_0's multi_logloss: 0.647471\n",
      "[358]\tvalid_0's multi_logloss: 0.647292\n",
      "[359]\tvalid_0's multi_logloss: 0.647109\n",
      "[360]\tvalid_0's multi_logloss: 0.646932\n",
      "[361]\tvalid_0's multi_logloss: 0.646752\n",
      "[362]\tvalid_0's multi_logloss: 0.646512\n",
      "[363]\tvalid_0's multi_logloss: 0.646168\n",
      "[364]\tvalid_0's multi_logloss: 0.645861\n",
      "[365]\tvalid_0's multi_logloss: 0.645714\n",
      "[366]\tvalid_0's multi_logloss: 0.645511\n",
      "[367]\tvalid_0's multi_logloss: 0.645264\n",
      "[368]\tvalid_0's multi_logloss: 0.645012\n",
      "[369]\tvalid_0's multi_logloss: 0.644874\n",
      "[370]\tvalid_0's multi_logloss: 0.644619\n",
      "[371]\tvalid_0's multi_logloss: 0.644499\n",
      "[372]\tvalid_0's multi_logloss: 0.644321\n",
      "[373]\tvalid_0's multi_logloss: 0.644143\n",
      "[374]\tvalid_0's multi_logloss: 0.644058\n",
      "[375]\tvalid_0's multi_logloss: 0.643791\n",
      "[376]\tvalid_0's multi_logloss: 0.643503\n",
      "[377]\tvalid_0's multi_logloss: 0.643244\n",
      "[378]\tvalid_0's multi_logloss: 0.643081\n",
      "[379]\tvalid_0's multi_logloss: 0.642806\n",
      "[380]\tvalid_0's multi_logloss: 0.642494\n",
      "[381]\tvalid_0's multi_logloss: 0.642271\n",
      "[382]\tvalid_0's multi_logloss: 0.641896\n",
      "[383]\tvalid_0's multi_logloss: 0.641697\n",
      "[384]\tvalid_0's multi_logloss: 0.641556\n",
      "[385]\tvalid_0's multi_logloss: 0.641319\n",
      "[386]\tvalid_0's multi_logloss: 0.641048\n",
      "[387]\tvalid_0's multi_logloss: 0.640805\n",
      "[388]\tvalid_0's multi_logloss: 0.640514\n",
      "[389]\tvalid_0's multi_logloss: 0.6404\n",
      "[390]\tvalid_0's multi_logloss: 0.640196\n",
      "[391]\tvalid_0's multi_logloss: 0.639938\n",
      "[392]\tvalid_0's multi_logloss: 0.639741\n",
      "[393]\tvalid_0's multi_logloss: 0.639575\n",
      "[394]\tvalid_0's multi_logloss: 0.639314\n",
      "[395]\tvalid_0's multi_logloss: 0.639088\n",
      "[396]\tvalid_0's multi_logloss: 0.638947\n",
      "[397]\tvalid_0's multi_logloss: 0.638707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398]\tvalid_0's multi_logloss: 0.638556\n",
      "[399]\tvalid_0's multi_logloss: 0.638396\n",
      "[400]\tvalid_0's multi_logloss: 0.638202\n",
      "[401]\tvalid_0's multi_logloss: 0.638043\n",
      "[402]\tvalid_0's multi_logloss: 0.637941\n",
      "[403]\tvalid_0's multi_logloss: 0.637783\n",
      "[404]\tvalid_0's multi_logloss: 0.63761\n",
      "[405]\tvalid_0's multi_logloss: 0.637405\n",
      "[406]\tvalid_0's multi_logloss: 0.637165\n",
      "[407]\tvalid_0's multi_logloss: 0.636957\n",
      "[408]\tvalid_0's multi_logloss: 0.636653\n",
      "[409]\tvalid_0's multi_logloss: 0.636349\n",
      "[410]\tvalid_0's multi_logloss: 0.636205\n",
      "[411]\tvalid_0's multi_logloss: 0.635868\n",
      "[412]\tvalid_0's multi_logloss: 0.635599\n",
      "[413]\tvalid_0's multi_logloss: 0.635292\n",
      "[414]\tvalid_0's multi_logloss: 0.635336\n",
      "[415]\tvalid_0's multi_logloss: 0.635115\n",
      "[416]\tvalid_0's multi_logloss: 0.634952\n",
      "[417]\tvalid_0's multi_logloss: 0.634881\n",
      "[418]\tvalid_0's multi_logloss: 0.634753\n",
      "[419]\tvalid_0's multi_logloss: 0.634527\n",
      "[420]\tvalid_0's multi_logloss: 0.634331\n",
      "[421]\tvalid_0's multi_logloss: 0.634256\n",
      "[422]\tvalid_0's multi_logloss: 0.634094\n",
      "[423]\tvalid_0's multi_logloss: 0.634082\n",
      "[424]\tvalid_0's multi_logloss: 0.633833\n",
      "[425]\tvalid_0's multi_logloss: 0.633611\n",
      "[426]\tvalid_0's multi_logloss: 0.633567\n",
      "[427]\tvalid_0's multi_logloss: 0.633432\n",
      "[428]\tvalid_0's multi_logloss: 0.633349\n",
      "[429]\tvalid_0's multi_logloss: 0.633104\n",
      "[430]\tvalid_0's multi_logloss: 0.632921\n",
      "[431]\tvalid_0's multi_logloss: 0.632781\n",
      "[432]\tvalid_0's multi_logloss: 0.632799\n",
      "[433]\tvalid_0's multi_logloss: 0.632734\n",
      "[434]\tvalid_0's multi_logloss: 0.632612\n",
      "[435]\tvalid_0's multi_logloss: 0.632445\n",
      "[436]\tvalid_0's multi_logloss: 0.632279\n",
      "[437]\tvalid_0's multi_logloss: 0.632083\n",
      "[438]\tvalid_0's multi_logloss: 0.631995\n",
      "[439]\tvalid_0's multi_logloss: 0.631893\n",
      "[440]\tvalid_0's multi_logloss: 0.631793\n",
      "[441]\tvalid_0's multi_logloss: 0.631732\n",
      "[442]\tvalid_0's multi_logloss: 0.631673\n",
      "[443]\tvalid_0's multi_logloss: 0.631564\n",
      "[444]\tvalid_0's multi_logloss: 0.631455\n",
      "[445]\tvalid_0's multi_logloss: 0.631456\n",
      "[446]\tvalid_0's multi_logloss: 0.63128\n",
      "[447]\tvalid_0's multi_logloss: 0.631138\n",
      "[448]\tvalid_0's multi_logloss: 0.630806\n",
      "[449]\tvalid_0's multi_logloss: 0.630434\n",
      "[450]\tvalid_0's multi_logloss: 0.63023\n",
      "[451]\tvalid_0's multi_logloss: 0.629975\n",
      "[452]\tvalid_0's multi_logloss: 0.629708\n",
      "[453]\tvalid_0's multi_logloss: 0.629743\n",
      "[454]\tvalid_0's multi_logloss: 0.629477\n",
      "[455]\tvalid_0's multi_logloss: 0.629245\n",
      "[456]\tvalid_0's multi_logloss: 0.629018\n",
      "[457]\tvalid_0's multi_logloss: 0.629012\n",
      "[458]\tvalid_0's multi_logloss: 0.628935\n",
      "[459]\tvalid_0's multi_logloss: 0.628769\n",
      "[460]\tvalid_0's multi_logloss: 0.628536\n",
      "[461]\tvalid_0's multi_logloss: 0.628461\n",
      "[462]\tvalid_0's multi_logloss: 0.628357\n",
      "[463]\tvalid_0's multi_logloss: 0.628227\n",
      "[464]\tvalid_0's multi_logloss: 0.628164\n",
      "[465]\tvalid_0's multi_logloss: 0.62807\n",
      "[466]\tvalid_0's multi_logloss: 0.627887\n",
      "[467]\tvalid_0's multi_logloss: 0.627793\n",
      "[468]\tvalid_0's multi_logloss: 0.627558\n",
      "[469]\tvalid_0's multi_logloss: 0.627479\n",
      "[470]\tvalid_0's multi_logloss: 0.627415\n",
      "[471]\tvalid_0's multi_logloss: 0.627065\n",
      "[472]\tvalid_0's multi_logloss: 0.626918\n",
      "[473]\tvalid_0's multi_logloss: 0.626777\n",
      "[474]\tvalid_0's multi_logloss: 0.626642\n",
      "[475]\tvalid_0's multi_logloss: 0.626525\n",
      "[476]\tvalid_0's multi_logloss: 0.626473\n",
      "[477]\tvalid_0's multi_logloss: 0.626423\n",
      "[478]\tvalid_0's multi_logloss: 0.626319\n",
      "[479]\tvalid_0's multi_logloss: 0.626085\n",
      "[480]\tvalid_0's multi_logloss: 0.626013\n",
      "[481]\tvalid_0's multi_logloss: 0.625886\n",
      "[482]\tvalid_0's multi_logloss: 0.625627\n",
      "[483]\tvalid_0's multi_logloss: 0.625451\n",
      "[484]\tvalid_0's multi_logloss: 0.625391\n",
      "[485]\tvalid_0's multi_logloss: 0.625249\n",
      "[486]\tvalid_0's multi_logloss: 0.625175\n",
      "[487]\tvalid_0's multi_logloss: 0.625065\n",
      "[488]\tvalid_0's multi_logloss: 0.624886\n",
      "[489]\tvalid_0's multi_logloss: 0.624832\n",
      "[490]\tvalid_0's multi_logloss: 0.624872\n",
      "[491]\tvalid_0's multi_logloss: 0.624875\n",
      "[492]\tvalid_0's multi_logloss: 0.624829\n",
      "[493]\tvalid_0's multi_logloss: 0.624692\n",
      "[494]\tvalid_0's multi_logloss: 0.624562\n",
      "[495]\tvalid_0's multi_logloss: 0.624296\n",
      "[496]\tvalid_0's multi_logloss: 0.624239\n",
      "[497]\tvalid_0's multi_logloss: 0.624143\n",
      "[498]\tvalid_0's multi_logloss: 0.624094\n",
      "[499]\tvalid_0's multi_logloss: 0.624035\n",
      "[500]\tvalid_0's multi_logloss: 0.623913\n",
      "[501]\tvalid_0's multi_logloss: 0.623877\n",
      "[502]\tvalid_0's multi_logloss: 0.623816\n",
      "[503]\tvalid_0's multi_logloss: 0.62384\n",
      "[504]\tvalid_0's multi_logloss: 0.623936\n",
      "[505]\tvalid_0's multi_logloss: 0.623966\n",
      "[506]\tvalid_0's multi_logloss: 0.623951\n",
      "[507]\tvalid_0's multi_logloss: 0.623988\n",
      "[508]\tvalid_0's multi_logloss: 0.623978\n",
      "[509]\tvalid_0's multi_logloss: 0.623941\n",
      "[510]\tvalid_0's multi_logloss: 0.623834\n",
      "[511]\tvalid_0's multi_logloss: 0.623818\n",
      "[512]\tvalid_0's multi_logloss: 0.623881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting=&#x27;gbdt&#x27;,\n",
       "               feature_fraction=0.6, force_col_wise=True,\n",
       "               lambda_l1=0.00019163693019842484,\n",
       "               lambda_l2=0.0027009967266884796, learning_rate=0.01,\n",
       "               n_estimators=1000, num_leaves=163, objective=&#x27;multiclass&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting=&#x27;gbdt&#x27;,\n",
       "               feature_fraction=0.6, force_col_wise=True,\n",
       "               lambda_l1=0.00019163693019842484,\n",
       "               lambda_l2=0.0027009967266884796, learning_rate=0.01,\n",
       "               n_estimators=1000, num_leaves=163, objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting='gbdt',\n",
       "               feature_fraction=0.6, force_col_wise=True,\n",
       "               lambda_l1=0.00019163693019842484,\n",
       "               lambda_l2=0.0027009967266884796, learning_rate=0.01,\n",
       "               n_estimators=1000, num_leaves=163, objective='multiclass')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, eval_set = (X_test, y_test), early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ff5b2",
   "metadata": {},
   "source": [
    "### feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56de9430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_lexicon_score_summary    1711\n",
       "sentiment_lexicon_score_review     1220\n",
       "summary_embeddings_330              587\n",
       "summary_embeddings_272              566\n",
       "topic_similarity_35                 507\n",
       "                                   ... \n",
       "tfidf_increase                        0\n",
       "tfidf_inexpensive                     0\n",
       "tfidf_infected                        0\n",
       "tfidf_inferior                        0\n",
       "punc_18                               0\n",
       "Length: 2223, dtype: int32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(index = model.feature_name_, data = model.feature_importances_).sort_values(ascending = False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1e5fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\feature_importances.pkl\"\n",
    "feature_importances.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eaff38",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e094ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f73107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test,y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eaeb805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\test_predictions.pkl\"\n",
    "pd.DataFrame({\"y_pred\":y_pred, \"y_test\":y_test}).to_pickle(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
