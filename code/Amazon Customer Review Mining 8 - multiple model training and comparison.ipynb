{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2735c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe543f",
   "metadata": {},
   "source": [
    "### top 300 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f9f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\feature_importances.pkl\"\n",
    "feature_importances = pd.read_pickle(path)\n",
    "feature_importances = pd.DataFrame(feature_importances.reset_index())\n",
    "top300 = feature_importances['index'][:300].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d49fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_lexicon_score_summary',\n",
       " 'sentiment_lexicon_score_review',\n",
       " 'summary_embeddings_330',\n",
       " 'summary_embeddings_272',\n",
       " 'topic_similarity_35',\n",
       " 'topic_similarity_6',\n",
       " 'summary_embeddings_295',\n",
       " 'review_embeddings_319',\n",
       " 'summary_embeddings_300',\n",
       " 'summary_embeddings_57']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top300[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938d0d3",
   "metadata": {},
   "source": [
    "### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b051cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\dataset.csv\")\n",
    "additional_features = pd.read_pickle(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\additional_features.pkl\")\n",
    "sentiment_lexicon_score = pd.read_pickle(r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\sentiment_lexicon_score.pkl\")\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\summary_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    summary_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\review_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    review_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\keyword_embeddings.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    keyword_embeddings = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    tfidf = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf_names.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    tfidf_names = np.load(f, allow_pickle=True)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\topic_words.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    topic_words = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\word_scores.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    word_scores = np.load(f)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\topic_similarity_scores.npy\"\n",
    "with open(path, 'rb') as f:\n",
    "    topic_similarity_scores = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681bca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['response'] = dataset.sentiment.map({\"POS\":1, \"NEU\":0,\"NEG\":-1})\n",
    "summary_embeddings_df = pd.DataFrame(summary_embeddings, columns = list(map(lambda value: f\"summary_embeddings_{value}\", range(summary_embeddings.shape[1]))))\n",
    "review_embeddings_df = pd.DataFrame(review_embeddings, columns = list(map(lambda value: f\"review_embeddings_{value}\", range(review_embeddings.shape[1]))))\n",
    "keyword_embeddings_df = pd.DataFrame(keyword_embeddings, columns = list(map(lambda value: f\"keyword_embeddings_{value}\", range(keyword_embeddings.shape[1]))))\n",
    "tfidf_df = pd.DataFrame(tfidf, columns = \"tfidf_\"+tfidf_names)\n",
    "tfidf_cols = [col for col in tfidf_df.columns if col[6:] in topic_words.flatten()]\n",
    "topic_similarity_scores_df = pd.DataFrame(topic_similarity_scores, columns = list(map(lambda value: f\"topic_similarity_{value}\", range(topic_similarity_scores.shape[1]))))\n",
    "features = pd.concat([additional_features.merge(sentiment_lexicon_score, on = \"reviewId\"),summary_embeddings_df,review_embeddings_df,keyword_embeddings_df,tfidf_df[tfidf_cols],topic_similarity_scores_df], axis = 1)\n",
    "features = features.drop(\"reviewId\", axis = 1)\n",
    "punc_feature_names = {'punc_!': 'punc_0', 'punc_\"': 'punc_1', 'punc_#': 'punc_2', 'punc_$': 'punc_3', 'punc_%': 'punc_4', 'punc_&': 'punc_5', \"punc_'\": 'punc_6', 'punc_(': 'punc_7', 'punc_)': 'punc_8', 'punc_*': 'punc_9', 'punc_+': 'punc_10', 'punc_,': 'punc_11', 'punc_-': 'punc_12', 'punc_.': 'punc_13', 'punc_/': 'punc_14', 'punc_:': 'punc_15', 'punc_;': 'punc_16', 'punc_<': 'punc_17', 'punc_=': 'punc_18', 'punc_>': 'punc_19', 'punc_?': 'punc_20', 'punc_@': 'punc_21', 'punc_[': 'punc_22', 'punc_\\\\': 'punc_23', 'punc_]': 'punc_24', 'punc_^': 'punc_25', 'punc__': 'punc_26', 'punc_`': 'punc_27', 'punc_{': 'punc_28', 'punc_|': 'punc_29', 'punc_}': 'punc_30', 'punc_~': 'punc_31'}\n",
    "features.rename(columns = punc_feature_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd44144",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features[top300]\n",
    "y = dataset['response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3e5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_lexicon_score_summary</th>\n",
       "      <th>sentiment_lexicon_score_review</th>\n",
       "      <th>summary_embeddings_330</th>\n",
       "      <th>summary_embeddings_272</th>\n",
       "      <th>topic_similarity_35</th>\n",
       "      <th>topic_similarity_6</th>\n",
       "      <th>summary_embeddings_295</th>\n",
       "      <th>review_embeddings_319</th>\n",
       "      <th>summary_embeddings_300</th>\n",
       "      <th>summary_embeddings_57</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_embeddings_130</th>\n",
       "      <th>summary_embeddings_61</th>\n",
       "      <th>summary_embeddings_217</th>\n",
       "      <th>summary_embeddings_269</th>\n",
       "      <th>summary_embeddings_241</th>\n",
       "      <th>keyword_embeddings_294</th>\n",
       "      <th>keyword_embeddings_36</th>\n",
       "      <th>keyword_embeddings_199</th>\n",
       "      <th>summary_embeddings_73</th>\n",
       "      <th>summary_embeddings_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.053025</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.163936</td>\n",
       "      <td>-0.009753</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>-5.386195e-08</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>-0.019801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096059</td>\n",
       "      <td>-0.016484</td>\n",
       "      <td>0.048990</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>-0.095429</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>0.062055</td>\n",
       "      <td>-0.064515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.086788</td>\n",
       "      <td>0.052484</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.136973</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>-5.037876e-08</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>-0.035315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060381</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.037481</td>\n",
       "      <td>0.032187</td>\n",
       "      <td>-0.113303</td>\n",
       "      <td>-0.063210</td>\n",
       "      <td>-0.067895</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.129004</td>\n",
       "      <td>0.009287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.240325</td>\n",
       "      <td>0.086877</td>\n",
       "      <td>0.095317</td>\n",
       "      <td>-5.776995e-08</td>\n",
       "      <td>-0.016994</td>\n",
       "      <td>-0.012606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040394</td>\n",
       "      <td>-0.110922</td>\n",
       "      <td>-0.050359</td>\n",
       "      <td>0.041080</td>\n",
       "      <td>-0.049910</td>\n",
       "      <td>-0.040518</td>\n",
       "      <td>-0.045201</td>\n",
       "      <td>-0.053216</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>-0.101141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.056525</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>0.178283</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-6.009654e-08</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162581</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.019479</td>\n",
       "      <td>-0.019074</td>\n",
       "      <td>-0.011995</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>-0.084640</td>\n",
       "      <td>0.043612</td>\n",
       "      <td>0.036232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.045518</td>\n",
       "      <td>0.023466</td>\n",
       "      <td>0.198467</td>\n",
       "      <td>0.102425</td>\n",
       "      <td>0.025269</td>\n",
       "      <td>-4.335865e-08</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-0.069371</td>\n",
       "      <td>-0.060756</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.021469</td>\n",
       "      <td>0.094012</td>\n",
       "      <td>0.044318</td>\n",
       "      <td>0.071187</td>\n",
       "      <td>-0.018752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>-0.092562</td>\n",
       "      <td>0.029032</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>-1.448907e-08</td>\n",
       "      <td>-0.111145</td>\n",
       "      <td>-0.056205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102875</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>-0.041810</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>-0.008710</td>\n",
       "      <td>-0.092448</td>\n",
       "      <td>0.015061</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>-0.020109</td>\n",
       "      <td>0.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.031087</td>\n",
       "      <td>-0.027294</td>\n",
       "      <td>0.118289</td>\n",
       "      <td>0.278527</td>\n",
       "      <td>0.030602</td>\n",
       "      <td>-4.413177e-08</td>\n",
       "      <td>-0.006407</td>\n",
       "      <td>-0.016710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>-0.046202</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>-0.023742</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>-0.025144</td>\n",
       "      <td>-0.046671</td>\n",
       "      <td>0.096399</td>\n",
       "      <td>-0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>-0.085862</td>\n",
       "      <td>0.222701</td>\n",
       "      <td>0.084716</td>\n",
       "      <td>0.071619</td>\n",
       "      <td>-4.731149e-08</td>\n",
       "      <td>0.144268</td>\n",
       "      <td>-0.058413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>-0.081254</td>\n",
       "      <td>-0.078389</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>0.075592</td>\n",
       "      <td>0.018067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.029618</td>\n",
       "      <td>0.073468</td>\n",
       "      <td>0.110183</td>\n",
       "      <td>0.055998</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>-4.689916e-08</td>\n",
       "      <td>-0.040872</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>-0.006235</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>-0.062403</td>\n",
       "      <td>0.047743</td>\n",
       "      <td>-0.015030</td>\n",
       "      <td>0.013991</td>\n",
       "      <td>-0.007235</td>\n",
       "      <td>0.122253</td>\n",
       "      <td>-0.049531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.099813</td>\n",
       "      <td>-0.115509</td>\n",
       "      <td>0.125282</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>-0.092059</td>\n",
       "      <td>-4.816015e-08</td>\n",
       "      <td>-0.041086</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055620</td>\n",
       "      <td>-0.025088</td>\n",
       "      <td>0.092557</td>\n",
       "      <td>-0.060840</td>\n",
       "      <td>-0.020660</td>\n",
       "      <td>0.047760</td>\n",
       "      <td>-0.029097</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>-0.012311</td>\n",
       "      <td>0.069521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4440 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment_lexicon_score_summary  sentiment_lexicon_score_review  \\\n",
       "0                            0.045455                        0.053025   \n",
       "1                            0.285714                        0.086788   \n",
       "2                            0.000000                        0.105263   \n",
       "3                            0.666667                        0.058333   \n",
       "4                            0.400000                        0.062500   \n",
       "...                               ...                             ...   \n",
       "4435                         0.000000                        1.000000   \n",
       "4436                         0.083333                        0.016949   \n",
       "4437                         0.400000                        0.127660   \n",
       "4438                         0.000000                        0.139706   \n",
       "4439                         0.166667                        0.071429   \n",
       "\n",
       "      summary_embeddings_330  summary_embeddings_272  topic_similarity_35  \\\n",
       "0                   0.042440                0.008029             0.163936   \n",
       "1                   0.052484                0.024354             0.136973   \n",
       "2                  -0.001403               -0.006016             0.240325   \n",
       "3                   0.056525               -0.016757             0.178283   \n",
       "4                   0.045518                0.023466             0.198467   \n",
       "...                      ...                     ...                  ...   \n",
       "4435               -0.007891               -0.092562             0.029032   \n",
       "4436                0.031087               -0.027294             0.118289   \n",
       "4437                0.025872               -0.085862             0.222701   \n",
       "4438                0.029618                0.073468             0.110183   \n",
       "4439                0.099813               -0.115509             0.125282   \n",
       "\n",
       "      topic_similarity_6  summary_embeddings_295  review_embeddings_319  \\\n",
       "0              -0.009753                0.050670          -5.386195e-08   \n",
       "1               0.031459                0.001173          -5.037876e-08   \n",
       "2               0.086877                0.095317          -5.776995e-08   \n",
       "3               0.027040               -0.000302          -6.009654e-08   \n",
       "4               0.102425                0.025269          -4.335865e-08   \n",
       "...                  ...                     ...                    ...   \n",
       "4435           -0.004933                0.022041          -1.448907e-08   \n",
       "4436            0.278527                0.030602          -4.413177e-08   \n",
       "4437            0.084716                0.071619          -4.731149e-08   \n",
       "4438            0.055998                0.013738          -4.689916e-08   \n",
       "4439            0.164683               -0.092059          -4.816015e-08   \n",
       "\n",
       "      summary_embeddings_300  summary_embeddings_57  ...  \\\n",
       "0                   0.017819              -0.019801  ...   \n",
       "1                   0.019186              -0.035315  ...   \n",
       "2                  -0.016994              -0.012606  ...   \n",
       "3                  -0.005012               0.001925  ...   \n",
       "4                   0.030786              -0.048000  ...   \n",
       "...                      ...                    ...  ...   \n",
       "4435               -0.111145              -0.056205  ...   \n",
       "4436               -0.006407              -0.016710  ...   \n",
       "4437                0.144268              -0.058413  ...   \n",
       "4438               -0.040872               0.026115  ...   \n",
       "4439               -0.041086               0.014865  ...   \n",
       "\n",
       "      summary_embeddings_130  summary_embeddings_61  summary_embeddings_217  \\\n",
       "0                  -0.096059              -0.016484                0.048990   \n",
       "1                  -0.060381               0.036702                0.037481   \n",
       "2                  -0.040394              -0.110922               -0.050359   \n",
       "3                   0.162581              -0.044337               -0.000521   \n",
       "4                   0.002908              -0.069371               -0.060756   \n",
       "...                      ...                    ...                     ...   \n",
       "4435                0.102875               0.003152               -0.041810   \n",
       "4436               -0.001544              -0.046202                0.009896   \n",
       "4437               -0.006275               0.011016                0.072200   \n",
       "4438                0.025791              -0.006235                0.047045   \n",
       "4439                0.055620              -0.025088                0.092557   \n",
       "\n",
       "      summary_embeddings_269  summary_embeddings_241  keyword_embeddings_294  \\\n",
       "0                   0.005784               -0.095429                0.008493   \n",
       "1                   0.032187               -0.113303               -0.063210   \n",
       "2                   0.041080               -0.049910               -0.040518   \n",
       "3                  -0.019479               -0.019074               -0.011995   \n",
       "4                   0.039053                0.008632               -0.021469   \n",
       "...                      ...                     ...                     ...   \n",
       "4435                0.003943               -0.008710               -0.092448   \n",
       "4436                0.003050               -0.023742                0.009109   \n",
       "4437                0.018580               -0.081254               -0.078389   \n",
       "4438               -0.062403                0.047743               -0.015030   \n",
       "4439               -0.060840               -0.020660                0.047760   \n",
       "\n",
       "      keyword_embeddings_36  keyword_embeddings_199  summary_embeddings_73  \\\n",
       "0                  0.019787               -0.004579               0.062055   \n",
       "1                 -0.067895                0.002200               0.129004   \n",
       "2                 -0.045201               -0.053216               0.020363   \n",
       "3                  0.035094               -0.084640               0.043612   \n",
       "4                  0.094012                0.044318               0.071187   \n",
       "...                     ...                     ...                    ...   \n",
       "4435               0.015061               -0.007283              -0.020109   \n",
       "4436              -0.025144               -0.046671               0.096399   \n",
       "4437               0.004795               -0.034365               0.075592   \n",
       "4438               0.013991               -0.007235               0.122253   \n",
       "4439              -0.029097                0.020986              -0.012311   \n",
       "\n",
       "      summary_embeddings_1  \n",
       "0                -0.064515  \n",
       "1                 0.009287  \n",
       "2                -0.101141  \n",
       "3                 0.036232  \n",
       "4                -0.018752  \n",
       "...                    ...  \n",
       "4435              0.028218  \n",
       "4436             -0.007330  \n",
       "4437              0.018067  \n",
       "4438             -0.049531  \n",
       "4439              0.069521  \n",
       "\n",
       "[4440 rows x 300 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d5ed2",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4262c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a4f4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Naive Bayes\",\"SVM\", \"Extra Trees\", \"Random Forest\", \"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3e3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c4226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc84758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3f52b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_model = ExtraTreesClassifier()\n",
    "etc_model.fit(X_train, y_train)\n",
    "y_pred = etc_model.predict(X_test)\n",
    "accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ce7c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "y_pred = rfc_model.predict(X_test)\n",
    "accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a84b1a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.05006\n",
      "[2]\tvalid_0's multi_logloss: 1.00876\n",
      "[3]\tvalid_0's multi_logloss: 0.974248\n",
      "[4]\tvalid_0's multi_logloss: 0.945331\n",
      "[5]\tvalid_0's multi_logloss: 0.921384\n",
      "[6]\tvalid_0's multi_logloss: 0.900344\n",
      "[7]\tvalid_0's multi_logloss: 0.881848\n",
      "[8]\tvalid_0's multi_logloss: 0.862436\n",
      "[9]\tvalid_0's multi_logloss: 0.848086\n",
      "[10]\tvalid_0's multi_logloss: 0.830149\n",
      "[11]\tvalid_0's multi_logloss: 0.816026\n",
      "[12]\tvalid_0's multi_logloss: 0.803636\n",
      "[13]\tvalid_0's multi_logloss: 0.792211\n",
      "[14]\tvalid_0's multi_logloss: 0.782818\n",
      "[15]\tvalid_0's multi_logloss: 0.771553\n",
      "[16]\tvalid_0's multi_logloss: 0.763342\n",
      "[17]\tvalid_0's multi_logloss: 0.756085\n",
      "[18]\tvalid_0's multi_logloss: 0.747924\n",
      "[19]\tvalid_0's multi_logloss: 0.741794\n",
      "[20]\tvalid_0's multi_logloss: 0.736829\n",
      "[21]\tvalid_0's multi_logloss: 0.732257\n",
      "[22]\tvalid_0's multi_logloss: 0.727119\n",
      "[23]\tvalid_0's multi_logloss: 0.721609\n",
      "[24]\tvalid_0's multi_logloss: 0.716983\n",
      "[25]\tvalid_0's multi_logloss: 0.713638\n",
      "[26]\tvalid_0's multi_logloss: 0.71036\n",
      "[27]\tvalid_0's multi_logloss: 0.707313\n",
      "[28]\tvalid_0's multi_logloss: 0.704686\n",
      "[29]\tvalid_0's multi_logloss: 0.702432\n",
      "[30]\tvalid_0's multi_logloss: 0.698123\n",
      "[31]\tvalid_0's multi_logloss: 0.694933\n",
      "[32]\tvalid_0's multi_logloss: 0.692352\n",
      "[33]\tvalid_0's multi_logloss: 0.689865\n",
      "[34]\tvalid_0's multi_logloss: 0.687303\n",
      "[35]\tvalid_0's multi_logloss: 0.685911\n",
      "[36]\tvalid_0's multi_logloss: 0.683432\n",
      "[37]\tvalid_0's multi_logloss: 0.681002\n",
      "[38]\tvalid_0's multi_logloss: 0.678623\n",
      "[39]\tvalid_0's multi_logloss: 0.67821\n",
      "[40]\tvalid_0's multi_logloss: 0.676654\n",
      "[41]\tvalid_0's multi_logloss: 0.675289\n",
      "[42]\tvalid_0's multi_logloss: 0.673698\n",
      "[43]\tvalid_0's multi_logloss: 0.67016\n",
      "[44]\tvalid_0's multi_logloss: 0.669192\n",
      "[45]\tvalid_0's multi_logloss: 0.669426\n",
      "[46]\tvalid_0's multi_logloss: 0.667366\n",
      "[47]\tvalid_0's multi_logloss: 0.667622\n",
      "[48]\tvalid_0's multi_logloss: 0.666725\n",
      "[49]\tvalid_0's multi_logloss: 0.666152\n",
      "[50]\tvalid_0's multi_logloss: 0.664419\n",
      "[51]\tvalid_0's multi_logloss: 0.664004\n",
      "[52]\tvalid_0's multi_logloss: 0.662803\n",
      "[53]\tvalid_0's multi_logloss: 0.66221\n",
      "[54]\tvalid_0's multi_logloss: 0.662734\n",
      "[55]\tvalid_0's multi_logloss: 0.661559\n",
      "[56]\tvalid_0's multi_logloss: 0.661761\n",
      "[57]\tvalid_0's multi_logloss: 0.660394\n",
      "[58]\tvalid_0's multi_logloss: 0.659821\n",
      "[59]\tvalid_0's multi_logloss: 0.659622\n",
      "[60]\tvalid_0's multi_logloss: 0.659058\n",
      "[61]\tvalid_0's multi_logloss: 0.658974\n",
      "[62]\tvalid_0's multi_logloss: 0.659012\n",
      "[63]\tvalid_0's multi_logloss: 0.659848\n",
      "[64]\tvalid_0's multi_logloss: 0.658839\n",
      "[65]\tvalid_0's multi_logloss: 0.658171\n",
      "[66]\tvalid_0's multi_logloss: 0.657765\n",
      "[67]\tvalid_0's multi_logloss: 0.657921\n",
      "[68]\tvalid_0's multi_logloss: 0.658105\n",
      "[69]\tvalid_0's multi_logloss: 0.658735\n",
      "[70]\tvalid_0's multi_logloss: 0.658275\n",
      "[71]\tvalid_0's multi_logloss: 0.658374\n",
      "[72]\tvalid_0's multi_logloss: 0.659026\n",
      "[73]\tvalid_0's multi_logloss: 0.659025\n",
      "[74]\tvalid_0's multi_logloss: 0.658113\n",
      "[75]\tvalid_0's multi_logloss: 0.658255\n",
      "[76]\tvalid_0's multi_logloss: 0.658017\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train,y_train, eval_set = (X_test, y_test), early_stopping_rounds = 10)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b290d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\":1000,\n",
    "    'num_leaves': 163,\n",
    "    'bagging_fraction': 0.80,\n",
    "    'lambda_l1': 0.00019163693019842484,\n",
    "    'lambda_l2': 0.0027009967266884796,\n",
    "    'feature_fraction': 0.60,\n",
    "    'boosting': 'gbdt',\n",
    "    \"learning_rate\":0.01,\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"max_depth\":  -1,\n",
    "    \"bagging_freq\": 5 ,                  # resamples rows at every k-th iteration\n",
    "    \"force_col_wise\":  True  ,                 # reduce memory cost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2edf78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00019163693019842484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019163693019842484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0027009967266884796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0027009967266884796\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[1]\tvalid_0's multi_logloss: 1.09388\n",
      "[2]\tvalid_0's multi_logloss: 1.08866\n",
      "[3]\tvalid_0's multi_logloss: 1.08344\n",
      "[4]\tvalid_0's multi_logloss: 1.07775\n",
      "[5]\tvalid_0's multi_logloss: 1.07243\n",
      "[6]\tvalid_0's multi_logloss: 1.06746\n",
      "[7]\tvalid_0's multi_logloss: 1.06249\n",
      "[8]\tvalid_0's multi_logloss: 1.05804\n",
      "[9]\tvalid_0's multi_logloss: 1.05317\n",
      "[10]\tvalid_0's multi_logloss: 1.04827\n",
      "[11]\tvalid_0's multi_logloss: 1.04349\n",
      "[12]\tvalid_0's multi_logloss: 1.03891\n",
      "[13]\tvalid_0's multi_logloss: 1.03413\n",
      "[14]\tvalid_0's multi_logloss: 1.02944\n",
      "[15]\tvalid_0's multi_logloss: 1.02465\n",
      "[16]\tvalid_0's multi_logloss: 1.02041\n",
      "[17]\tvalid_0's multi_logloss: 1.01607\n",
      "[18]\tvalid_0's multi_logloss: 1.01162\n",
      "[19]\tvalid_0's multi_logloss: 1.00747\n",
      "[20]\tvalid_0's multi_logloss: 1.00369\n",
      "[21]\tvalid_0's multi_logloss: 0.999182\n",
      "[22]\tvalid_0's multi_logloss: 0.995012\n",
      "[23]\tvalid_0's multi_logloss: 0.990903\n",
      "[24]\tvalid_0's multi_logloss: 0.986919\n",
      "[25]\tvalid_0's multi_logloss: 0.982972\n",
      "[26]\tvalid_0's multi_logloss: 0.979094\n",
      "[27]\tvalid_0's multi_logloss: 0.975635\n",
      "[28]\tvalid_0's multi_logloss: 0.972291\n",
      "[29]\tvalid_0's multi_logloss: 0.969014\n",
      "[30]\tvalid_0's multi_logloss: 0.965627\n",
      "[31]\tvalid_0's multi_logloss: 0.962353\n",
      "[32]\tvalid_0's multi_logloss: 0.9592\n",
      "[33]\tvalid_0's multi_logloss: 0.956181\n",
      "[34]\tvalid_0's multi_logloss: 0.952745\n",
      "[35]\tvalid_0's multi_logloss: 0.949338\n",
      "[36]\tvalid_0's multi_logloss: 0.946099\n",
      "[37]\tvalid_0's multi_logloss: 0.942964\n",
      "[38]\tvalid_0's multi_logloss: 0.939909\n",
      "[39]\tvalid_0's multi_logloss: 0.936622\n",
      "[40]\tvalid_0's multi_logloss: 0.933402\n",
      "[41]\tvalid_0's multi_logloss: 0.93079\n",
      "[42]\tvalid_0's multi_logloss: 0.927993\n",
      "[43]\tvalid_0's multi_logloss: 0.924731\n",
      "[44]\tvalid_0's multi_logloss: 0.921631\n",
      "[45]\tvalid_0's multi_logloss: 0.918711\n",
      "[46]\tvalid_0's multi_logloss: 0.91586\n",
      "[47]\tvalid_0's multi_logloss: 0.913168\n",
      "[48]\tvalid_0's multi_logloss: 0.910179\n",
      "[49]\tvalid_0's multi_logloss: 0.907626\n",
      "[50]\tvalid_0's multi_logloss: 0.904916\n",
      "[51]\tvalid_0's multi_logloss: 0.902492\n",
      "[52]\tvalid_0's multi_logloss: 0.899928\n",
      "[53]\tvalid_0's multi_logloss: 0.897289\n",
      "[54]\tvalid_0's multi_logloss: 0.894654\n",
      "[55]\tvalid_0's multi_logloss: 0.892179\n",
      "[56]\tvalid_0's multi_logloss: 0.889756\n",
      "[57]\tvalid_0's multi_logloss: 0.88755\n",
      "[58]\tvalid_0's multi_logloss: 0.884818\n",
      "[59]\tvalid_0's multi_logloss: 0.882498\n",
      "[60]\tvalid_0's multi_logloss: 0.88025\n",
      "[61]\tvalid_0's multi_logloss: 0.878013\n",
      "[62]\tvalid_0's multi_logloss: 0.875623\n",
      "[63]\tvalid_0's multi_logloss: 0.873331\n",
      "[64]\tvalid_0's multi_logloss: 0.871235\n",
      "[65]\tvalid_0's multi_logloss: 0.868882\n",
      "[66]\tvalid_0's multi_logloss: 0.866401\n",
      "[67]\tvalid_0's multi_logloss: 0.864292\n",
      "[68]\tvalid_0's multi_logloss: 0.862222\n",
      "[69]\tvalid_0's multi_logloss: 0.85984\n",
      "[70]\tvalid_0's multi_logloss: 0.85758\n",
      "[71]\tvalid_0's multi_logloss: 0.855238\n",
      "[72]\tvalid_0's multi_logloss: 0.853008\n",
      "[73]\tvalid_0's multi_logloss: 0.850857\n",
      "[74]\tvalid_0's multi_logloss: 0.848651\n",
      "[75]\tvalid_0's multi_logloss: 0.846548\n",
      "[76]\tvalid_0's multi_logloss: 0.8447\n",
      "[77]\tvalid_0's multi_logloss: 0.842566\n",
      "[78]\tvalid_0's multi_logloss: 0.840766\n",
      "[79]\tvalid_0's multi_logloss: 0.838679\n",
      "[80]\tvalid_0's multi_logloss: 0.836895\n",
      "[81]\tvalid_0's multi_logloss: 0.835239\n",
      "[82]\tvalid_0's multi_logloss: 0.833389\n",
      "[83]\tvalid_0's multi_logloss: 0.831644\n",
      "[84]\tvalid_0's multi_logloss: 0.829836\n",
      "[85]\tvalid_0's multi_logloss: 0.827969\n",
      "[86]\tvalid_0's multi_logloss: 0.826151\n",
      "[87]\tvalid_0's multi_logloss: 0.824261\n",
      "[88]\tvalid_0's multi_logloss: 0.822599\n",
      "[89]\tvalid_0's multi_logloss: 0.821137\n",
      "[90]\tvalid_0's multi_logloss: 0.819455\n",
      "[91]\tvalid_0's multi_logloss: 0.817783\n",
      "[92]\tvalid_0's multi_logloss: 0.816065\n",
      "[93]\tvalid_0's multi_logloss: 0.814423\n",
      "[94]\tvalid_0's multi_logloss: 0.81289\n",
      "[95]\tvalid_0's multi_logloss: 0.81117\n",
      "[96]\tvalid_0's multi_logloss: 0.809743\n",
      "[97]\tvalid_0's multi_logloss: 0.808072\n",
      "[98]\tvalid_0's multi_logloss: 0.806391\n",
      "[99]\tvalid_0's multi_logloss: 0.80472\n",
      "[100]\tvalid_0's multi_logloss: 0.803142\n",
      "[101]\tvalid_0's multi_logloss: 0.801637\n",
      "[102]\tvalid_0's multi_logloss: 0.800188\n",
      "[103]\tvalid_0's multi_logloss: 0.798674\n",
      "[104]\tvalid_0's multi_logloss: 0.797342\n",
      "[105]\tvalid_0's multi_logloss: 0.795809\n",
      "[106]\tvalid_0's multi_logloss: 0.794469\n",
      "[107]\tvalid_0's multi_logloss: 0.792994\n",
      "[108]\tvalid_0's multi_logloss: 0.791679\n",
      "[109]\tvalid_0's multi_logloss: 0.790443\n",
      "[110]\tvalid_0's multi_logloss: 0.789189\n",
      "[111]\tvalid_0's multi_logloss: 0.787587\n",
      "[112]\tvalid_0's multi_logloss: 0.786443\n",
      "[113]\tvalid_0's multi_logloss: 0.785168\n",
      "[114]\tvalid_0's multi_logloss: 0.783988\n",
      "[115]\tvalid_0's multi_logloss: 0.782899\n",
      "[116]\tvalid_0's multi_logloss: 0.781533\n",
      "[117]\tvalid_0's multi_logloss: 0.780129\n",
      "[118]\tvalid_0's multi_logloss: 0.778689\n",
      "[119]\tvalid_0's multi_logloss: 0.777447\n",
      "[120]\tvalid_0's multi_logloss: 0.776221\n",
      "[121]\tvalid_0's multi_logloss: 0.774915\n",
      "[122]\tvalid_0's multi_logloss: 0.77369\n",
      "[123]\tvalid_0's multi_logloss: 0.772404\n",
      "[124]\tvalid_0's multi_logloss: 0.771099\n",
      "[125]\tvalid_0's multi_logloss: 0.769964\n",
      "[126]\tvalid_0's multi_logloss: 0.768931\n",
      "[127]\tvalid_0's multi_logloss: 0.767923\n",
      "[128]\tvalid_0's multi_logloss: 0.767021\n",
      "[129]\tvalid_0's multi_logloss: 0.765716\n",
      "[130]\tvalid_0's multi_logloss: 0.76453\n",
      "[131]\tvalid_0's multi_logloss: 0.763318\n",
      "[132]\tvalid_0's multi_logloss: 0.762318\n",
      "[133]\tvalid_0's multi_logloss: 0.761225\n",
      "[134]\tvalid_0's multi_logloss: 0.760168\n",
      "[135]\tvalid_0's multi_logloss: 0.759157\n",
      "[136]\tvalid_0's multi_logloss: 0.757993\n",
      "[137]\tvalid_0's multi_logloss: 0.756808\n",
      "[138]\tvalid_0's multi_logloss: 0.755843\n",
      "[139]\tvalid_0's multi_logloss: 0.754551\n",
      "[140]\tvalid_0's multi_logloss: 0.753552\n",
      "[141]\tvalid_0's multi_logloss: 0.752309\n",
      "[142]\tvalid_0's multi_logloss: 0.751252\n",
      "[143]\tvalid_0's multi_logloss: 0.750009\n",
      "[144]\tvalid_0's multi_logloss: 0.748883\n",
      "[145]\tvalid_0's multi_logloss: 0.747906\n",
      "[146]\tvalid_0's multi_logloss: 0.746729\n",
      "[147]\tvalid_0's multi_logloss: 0.745603\n",
      "[148]\tvalid_0's multi_logloss: 0.744649\n",
      "[149]\tvalid_0's multi_logloss: 0.743635\n",
      "[150]\tvalid_0's multi_logloss: 0.742649\n",
      "[151]\tvalid_0's multi_logloss: 0.741718\n",
      "[152]\tvalid_0's multi_logloss: 0.740629\n",
      "[153]\tvalid_0's multi_logloss: 0.739651\n",
      "[154]\tvalid_0's multi_logloss: 0.738588\n",
      "[155]\tvalid_0's multi_logloss: 0.737534\n",
      "[156]\tvalid_0's multi_logloss: 0.736572\n",
      "[157]\tvalid_0's multi_logloss: 0.735714\n",
      "[158]\tvalid_0's multi_logloss: 0.734721\n",
      "[159]\tvalid_0's multi_logloss: 0.733931\n",
      "[160]\tvalid_0's multi_logloss: 0.733032\n",
      "[161]\tvalid_0's multi_logloss: 0.73209\n",
      "[162]\tvalid_0's multi_logloss: 0.731508\n",
      "[163]\tvalid_0's multi_logloss: 0.73064\n",
      "[164]\tvalid_0's multi_logloss: 0.729736\n",
      "[165]\tvalid_0's multi_logloss: 0.72885\n",
      "[166]\tvalid_0's multi_logloss: 0.727849\n",
      "[167]\tvalid_0's multi_logloss: 0.727025\n",
      "[168]\tvalid_0's multi_logloss: 0.726177\n",
      "[169]\tvalid_0's multi_logloss: 0.725416\n",
      "[170]\tvalid_0's multi_logloss: 0.72466\n",
      "[171]\tvalid_0's multi_logloss: 0.723828\n",
      "[172]\tvalid_0's multi_logloss: 0.72301\n",
      "[173]\tvalid_0's multi_logloss: 0.722179\n",
      "[174]\tvalid_0's multi_logloss: 0.721313\n",
      "[175]\tvalid_0's multi_logloss: 0.720348\n",
      "[176]\tvalid_0's multi_logloss: 0.719597\n",
      "[177]\tvalid_0's multi_logloss: 0.718821\n",
      "[178]\tvalid_0's multi_logloss: 0.718168\n",
      "[179]\tvalid_0's multi_logloss: 0.717482\n",
      "[180]\tvalid_0's multi_logloss: 0.716752\n",
      "[181]\tvalid_0's multi_logloss: 0.715928\n",
      "[182]\tvalid_0's multi_logloss: 0.715178\n",
      "[183]\tvalid_0's multi_logloss: 0.714304\n",
      "[184]\tvalid_0's multi_logloss: 0.713533\n",
      "[185]\tvalid_0's multi_logloss: 0.712859\n",
      "[186]\tvalid_0's multi_logloss: 0.712154\n",
      "[187]\tvalid_0's multi_logloss: 0.71169\n",
      "[188]\tvalid_0's multi_logloss: 0.711114\n",
      "[189]\tvalid_0's multi_logloss: 0.710472\n",
      "[190]\tvalid_0's multi_logloss: 0.709823\n",
      "[191]\tvalid_0's multi_logloss: 0.709184\n",
      "[192]\tvalid_0's multi_logloss: 0.708604\n",
      "[193]\tvalid_0's multi_logloss: 0.708165\n",
      "[194]\tvalid_0's multi_logloss: 0.707492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195]\tvalid_0's multi_logloss: 0.706859\n",
      "[196]\tvalid_0's multi_logloss: 0.706127\n",
      "[197]\tvalid_0's multi_logloss: 0.705416\n",
      "[198]\tvalid_0's multi_logloss: 0.704591\n",
      "[199]\tvalid_0's multi_logloss: 0.703892\n",
      "[200]\tvalid_0's multi_logloss: 0.703302\n",
      "[201]\tvalid_0's multi_logloss: 0.70259\n",
      "[202]\tvalid_0's multi_logloss: 0.702033\n",
      "[203]\tvalid_0's multi_logloss: 0.701389\n",
      "[204]\tvalid_0's multi_logloss: 0.700742\n",
      "[205]\tvalid_0's multi_logloss: 0.70013\n",
      "[206]\tvalid_0's multi_logloss: 0.699344\n",
      "[207]\tvalid_0's multi_logloss: 0.698686\n",
      "[208]\tvalid_0's multi_logloss: 0.697817\n",
      "[209]\tvalid_0's multi_logloss: 0.697205\n",
      "[210]\tvalid_0's multi_logloss: 0.696597\n",
      "[211]\tvalid_0's multi_logloss: 0.695918\n",
      "[212]\tvalid_0's multi_logloss: 0.695209\n",
      "[213]\tvalid_0's multi_logloss: 0.694554\n",
      "[214]\tvalid_0's multi_logloss: 0.693842\n",
      "[215]\tvalid_0's multi_logloss: 0.69313\n",
      "[216]\tvalid_0's multi_logloss: 0.692691\n",
      "[217]\tvalid_0's multi_logloss: 0.69207\n",
      "[218]\tvalid_0's multi_logloss: 0.691443\n",
      "[219]\tvalid_0's multi_logloss: 0.690887\n",
      "[220]\tvalid_0's multi_logloss: 0.690455\n",
      "[221]\tvalid_0's multi_logloss: 0.689959\n",
      "[222]\tvalid_0's multi_logloss: 0.689336\n",
      "[223]\tvalid_0's multi_logloss: 0.688734\n",
      "[224]\tvalid_0's multi_logloss: 0.688187\n",
      "[225]\tvalid_0's multi_logloss: 0.687729\n",
      "[226]\tvalid_0's multi_logloss: 0.687096\n",
      "[227]\tvalid_0's multi_logloss: 0.686475\n",
      "[228]\tvalid_0's multi_logloss: 0.686169\n",
      "[229]\tvalid_0's multi_logloss: 0.685675\n",
      "[230]\tvalid_0's multi_logloss: 0.685107\n",
      "[231]\tvalid_0's multi_logloss: 0.684592\n",
      "[232]\tvalid_0's multi_logloss: 0.684013\n",
      "[233]\tvalid_0's multi_logloss: 0.683409\n",
      "[234]\tvalid_0's multi_logloss: 0.682919\n",
      "[235]\tvalid_0's multi_logloss: 0.682429\n",
      "[236]\tvalid_0's multi_logloss: 0.681994\n",
      "[237]\tvalid_0's multi_logloss: 0.681343\n",
      "[238]\tvalid_0's multi_logloss: 0.680755\n",
      "[239]\tvalid_0's multi_logloss: 0.680189\n",
      "[240]\tvalid_0's multi_logloss: 0.679634\n",
      "[241]\tvalid_0's multi_logloss: 0.679063\n",
      "[242]\tvalid_0's multi_logloss: 0.67848\n",
      "[243]\tvalid_0's multi_logloss: 0.677954\n",
      "[244]\tvalid_0's multi_logloss: 0.677326\n",
      "[245]\tvalid_0's multi_logloss: 0.676952\n",
      "[246]\tvalid_0's multi_logloss: 0.676541\n",
      "[247]\tvalid_0's multi_logloss: 0.67614\n",
      "[248]\tvalid_0's multi_logloss: 0.675689\n",
      "[249]\tvalid_0's multi_logloss: 0.67522\n",
      "[250]\tvalid_0's multi_logloss: 0.674743\n",
      "[251]\tvalid_0's multi_logloss: 0.674223\n",
      "[252]\tvalid_0's multi_logloss: 0.673782\n",
      "[253]\tvalid_0's multi_logloss: 0.673458\n",
      "[254]\tvalid_0's multi_logloss: 0.673111\n",
      "[255]\tvalid_0's multi_logloss: 0.672683\n",
      "[256]\tvalid_0's multi_logloss: 0.672238\n",
      "[257]\tvalid_0's multi_logloss: 0.671954\n",
      "[258]\tvalid_0's multi_logloss: 0.671526\n",
      "[259]\tvalid_0's multi_logloss: 0.671028\n",
      "[260]\tvalid_0's multi_logloss: 0.670576\n",
      "[261]\tvalid_0's multi_logloss: 0.670114\n",
      "[262]\tvalid_0's multi_logloss: 0.669657\n",
      "[263]\tvalid_0's multi_logloss: 0.669204\n",
      "[264]\tvalid_0's multi_logloss: 0.668812\n",
      "[265]\tvalid_0's multi_logloss: 0.668426\n",
      "[266]\tvalid_0's multi_logloss: 0.668172\n",
      "[267]\tvalid_0's multi_logloss: 0.667696\n",
      "[268]\tvalid_0's multi_logloss: 0.66733\n",
      "[269]\tvalid_0's multi_logloss: 0.667039\n",
      "[270]\tvalid_0's multi_logloss: 0.666754\n",
      "[271]\tvalid_0's multi_logloss: 0.666407\n",
      "[272]\tvalid_0's multi_logloss: 0.665981\n",
      "[273]\tvalid_0's multi_logloss: 0.66552\n",
      "[274]\tvalid_0's multi_logloss: 0.665077\n",
      "[275]\tvalid_0's multi_logloss: 0.66448\n",
      "[276]\tvalid_0's multi_logloss: 0.66402\n",
      "[277]\tvalid_0's multi_logloss: 0.663719\n",
      "[278]\tvalid_0's multi_logloss: 0.663492\n",
      "[279]\tvalid_0's multi_logloss: 0.663057\n",
      "[280]\tvalid_0's multi_logloss: 0.662737\n",
      "[281]\tvalid_0's multi_logloss: 0.662488\n",
      "[282]\tvalid_0's multi_logloss: 0.662091\n",
      "[283]\tvalid_0's multi_logloss: 0.661734\n",
      "[284]\tvalid_0's multi_logloss: 0.661443\n",
      "[285]\tvalid_0's multi_logloss: 0.661004\n",
      "[286]\tvalid_0's multi_logloss: 0.660699\n",
      "[287]\tvalid_0's multi_logloss: 0.660415\n",
      "[288]\tvalid_0's multi_logloss: 0.660085\n",
      "[289]\tvalid_0's multi_logloss: 0.659689\n",
      "[290]\tvalid_0's multi_logloss: 0.659426\n",
      "[291]\tvalid_0's multi_logloss: 0.658964\n",
      "[292]\tvalid_0's multi_logloss: 0.658574\n",
      "[293]\tvalid_0's multi_logloss: 0.658255\n",
      "[294]\tvalid_0's multi_logloss: 0.6579\n",
      "[295]\tvalid_0's multi_logloss: 0.657491\n",
      "[296]\tvalid_0's multi_logloss: 0.657227\n",
      "[297]\tvalid_0's multi_logloss: 0.656998\n",
      "[298]\tvalid_0's multi_logloss: 0.656683\n",
      "[299]\tvalid_0's multi_logloss: 0.656523\n",
      "[300]\tvalid_0's multi_logloss: 0.656264\n",
      "[301]\tvalid_0's multi_logloss: 0.655904\n",
      "[302]\tvalid_0's multi_logloss: 0.655665\n",
      "[303]\tvalid_0's multi_logloss: 0.655354\n",
      "[304]\tvalid_0's multi_logloss: 0.655093\n",
      "[305]\tvalid_0's multi_logloss: 0.654866\n",
      "[306]\tvalid_0's multi_logloss: 0.6544\n",
      "[307]\tvalid_0's multi_logloss: 0.654093\n",
      "[308]\tvalid_0's multi_logloss: 0.653797\n",
      "[309]\tvalid_0's multi_logloss: 0.653472\n",
      "[310]\tvalid_0's multi_logloss: 0.653166\n",
      "[311]\tvalid_0's multi_logloss: 0.653068\n",
      "[312]\tvalid_0's multi_logloss: 0.652724\n",
      "[313]\tvalid_0's multi_logloss: 0.652466\n",
      "[314]\tvalid_0's multi_logloss: 0.652079\n",
      "[315]\tvalid_0's multi_logloss: 0.651846\n",
      "[316]\tvalid_0's multi_logloss: 0.651702\n",
      "[317]\tvalid_0's multi_logloss: 0.651386\n",
      "[318]\tvalid_0's multi_logloss: 0.6511\n",
      "[319]\tvalid_0's multi_logloss: 0.650863\n",
      "[320]\tvalid_0's multi_logloss: 0.650589\n",
      "[321]\tvalid_0's multi_logloss: 0.650402\n",
      "[322]\tvalid_0's multi_logloss: 0.650188\n",
      "[323]\tvalid_0's multi_logloss: 0.649981\n",
      "[324]\tvalid_0's multi_logloss: 0.649688\n",
      "[325]\tvalid_0's multi_logloss: 0.649479\n",
      "[326]\tvalid_0's multi_logloss: 0.649084\n",
      "[327]\tvalid_0's multi_logloss: 0.648825\n",
      "[328]\tvalid_0's multi_logloss: 0.648539\n",
      "[329]\tvalid_0's multi_logloss: 0.648192\n",
      "[330]\tvalid_0's multi_logloss: 0.648029\n",
      "[331]\tvalid_0's multi_logloss: 0.647764\n",
      "[332]\tvalid_0's multi_logloss: 0.647604\n",
      "[333]\tvalid_0's multi_logloss: 0.647406\n",
      "[334]\tvalid_0's multi_logloss: 0.6472\n",
      "[335]\tvalid_0's multi_logloss: 0.646993\n",
      "[336]\tvalid_0's multi_logloss: 0.646768\n",
      "[337]\tvalid_0's multi_logloss: 0.646358\n",
      "[338]\tvalid_0's multi_logloss: 0.646274\n",
      "[339]\tvalid_0's multi_logloss: 0.646073\n",
      "[340]\tvalid_0's multi_logloss: 0.645944\n",
      "[341]\tvalid_0's multi_logloss: 0.645666\n",
      "[342]\tvalid_0's multi_logloss: 0.645499\n",
      "[343]\tvalid_0's multi_logloss: 0.645265\n",
      "[344]\tvalid_0's multi_logloss: 0.645043\n",
      "[345]\tvalid_0's multi_logloss: 0.644827\n",
      "[346]\tvalid_0's multi_logloss: 0.644606\n",
      "[347]\tvalid_0's multi_logloss: 0.644372\n",
      "[348]\tvalid_0's multi_logloss: 0.644027\n",
      "[349]\tvalid_0's multi_logloss: 0.643857\n",
      "[350]\tvalid_0's multi_logloss: 0.64364\n",
      "[351]\tvalid_0's multi_logloss: 0.643414\n",
      "[352]\tvalid_0's multi_logloss: 0.643355\n",
      "[353]\tvalid_0's multi_logloss: 0.643086\n",
      "[354]\tvalid_0's multi_logloss: 0.642953\n",
      "[355]\tvalid_0's multi_logloss: 0.642837\n",
      "[356]\tvalid_0's multi_logloss: 0.642486\n",
      "[357]\tvalid_0's multi_logloss: 0.642276\n",
      "[358]\tvalid_0's multi_logloss: 0.642131\n",
      "[359]\tvalid_0's multi_logloss: 0.641989\n",
      "[360]\tvalid_0's multi_logloss: 0.64184\n",
      "[361]\tvalid_0's multi_logloss: 0.641732\n",
      "[362]\tvalid_0's multi_logloss: 0.641416\n",
      "[363]\tvalid_0's multi_logloss: 0.641242\n",
      "[364]\tvalid_0's multi_logloss: 0.641098\n",
      "[365]\tvalid_0's multi_logloss: 0.640854\n",
      "[366]\tvalid_0's multi_logloss: 0.640568\n",
      "[367]\tvalid_0's multi_logloss: 0.64039\n",
      "[368]\tvalid_0's multi_logloss: 0.640154\n",
      "[369]\tvalid_0's multi_logloss: 0.639929\n",
      "[370]\tvalid_0's multi_logloss: 0.639828\n",
      "[371]\tvalid_0's multi_logloss: 0.639662\n",
      "[372]\tvalid_0's multi_logloss: 0.639451\n",
      "[373]\tvalid_0's multi_logloss: 0.639251\n",
      "[374]\tvalid_0's multi_logloss: 0.639175\n",
      "[375]\tvalid_0's multi_logloss: 0.639058\n",
      "[376]\tvalid_0's multi_logloss: 0.638816\n",
      "[377]\tvalid_0's multi_logloss: 0.638587\n",
      "[378]\tvalid_0's multi_logloss: 0.638427\n",
      "[379]\tvalid_0's multi_logloss: 0.638325\n",
      "[380]\tvalid_0's multi_logloss: 0.638203\n",
      "[381]\tvalid_0's multi_logloss: 0.637996\n",
      "[382]\tvalid_0's multi_logloss: 0.637761\n",
      "[383]\tvalid_0's multi_logloss: 0.637666\n",
      "[384]\tvalid_0's multi_logloss: 0.637481\n",
      "[385]\tvalid_0's multi_logloss: 0.637381\n",
      "[386]\tvalid_0's multi_logloss: 0.637301\n",
      "[387]\tvalid_0's multi_logloss: 0.637166\n",
      "[388]\tvalid_0's multi_logloss: 0.637041\n",
      "[389]\tvalid_0's multi_logloss: 0.636782\n",
      "[390]\tvalid_0's multi_logloss: 0.636531\n",
      "[391]\tvalid_0's multi_logloss: 0.636432\n",
      "[392]\tvalid_0's multi_logloss: 0.636196\n",
      "[393]\tvalid_0's multi_logloss: 0.636043\n",
      "[394]\tvalid_0's multi_logloss: 0.635954\n",
      "[395]\tvalid_0's multi_logloss: 0.635695\n",
      "[396]\tvalid_0's multi_logloss: 0.635568\n",
      "[397]\tvalid_0's multi_logloss: 0.635482\n",
      "[398]\tvalid_0's multi_logloss: 0.635268\n",
      "[399]\tvalid_0's multi_logloss: 0.635079\n",
      "[400]\tvalid_0's multi_logloss: 0.63495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[401]\tvalid_0's multi_logloss: 0.634803\n",
      "[402]\tvalid_0's multi_logloss: 0.634781\n",
      "[403]\tvalid_0's multi_logloss: 0.634636\n",
      "[404]\tvalid_0's multi_logloss: 0.634495\n",
      "[405]\tvalid_0's multi_logloss: 0.634516\n",
      "[406]\tvalid_0's multi_logloss: 0.6344\n",
      "[407]\tvalid_0's multi_logloss: 0.634047\n",
      "[408]\tvalid_0's multi_logloss: 0.63385\n",
      "[409]\tvalid_0's multi_logloss: 0.633572\n",
      "[410]\tvalid_0's multi_logloss: 0.633437\n",
      "[411]\tvalid_0's multi_logloss: 0.633374\n",
      "[412]\tvalid_0's multi_logloss: 0.633134\n",
      "[413]\tvalid_0's multi_logloss: 0.632971\n",
      "[414]\tvalid_0's multi_logloss: 0.632859\n",
      "[415]\tvalid_0's multi_logloss: 0.632724\n",
      "[416]\tvalid_0's multi_logloss: 0.632547\n",
      "[417]\tvalid_0's multi_logloss: 0.632259\n",
      "[418]\tvalid_0's multi_logloss: 0.632131\n",
      "[419]\tvalid_0's multi_logloss: 0.631994\n",
      "[420]\tvalid_0's multi_logloss: 0.631864\n",
      "[421]\tvalid_0's multi_logloss: 0.631715\n",
      "[422]\tvalid_0's multi_logloss: 0.631663\n",
      "[423]\tvalid_0's multi_logloss: 0.631545\n",
      "[424]\tvalid_0's multi_logloss: 0.631554\n",
      "[425]\tvalid_0's multi_logloss: 0.631573\n",
      "[426]\tvalid_0's multi_logloss: 0.631441\n",
      "[427]\tvalid_0's multi_logloss: 0.631334\n",
      "[428]\tvalid_0's multi_logloss: 0.631291\n",
      "[429]\tvalid_0's multi_logloss: 0.631338\n",
      "[430]\tvalid_0's multi_logloss: 0.631248\n",
      "[431]\tvalid_0's multi_logloss: 0.63127\n",
      "[432]\tvalid_0's multi_logloss: 0.631258\n",
      "[433]\tvalid_0's multi_logloss: 0.63122\n",
      "[434]\tvalid_0's multi_logloss: 0.631212\n",
      "[435]\tvalid_0's multi_logloss: 0.631164\n",
      "[436]\tvalid_0's multi_logloss: 0.631118\n",
      "[437]\tvalid_0's multi_logloss: 0.630904\n",
      "[438]\tvalid_0's multi_logloss: 0.630814\n",
      "[439]\tvalid_0's multi_logloss: 0.630796\n",
      "[440]\tvalid_0's multi_logloss: 0.630551\n",
      "[441]\tvalid_0's multi_logloss: 0.630487\n",
      "[442]\tvalid_0's multi_logloss: 0.630371\n",
      "[443]\tvalid_0's multi_logloss: 0.630215\n",
      "[444]\tvalid_0's multi_logloss: 0.630179\n",
      "[445]\tvalid_0's multi_logloss: 0.63004\n",
      "[446]\tvalid_0's multi_logloss: 0.629936\n",
      "[447]\tvalid_0's multi_logloss: 0.629865\n",
      "[448]\tvalid_0's multi_logloss: 0.629796\n",
      "[449]\tvalid_0's multi_logloss: 0.629457\n",
      "[450]\tvalid_0's multi_logloss: 0.629333\n",
      "[451]\tvalid_0's multi_logloss: 0.629186\n",
      "[452]\tvalid_0's multi_logloss: 0.629132\n",
      "[453]\tvalid_0's multi_logloss: 0.629185\n",
      "[454]\tvalid_0's multi_logloss: 0.628986\n",
      "[455]\tvalid_0's multi_logloss: 0.628862\n",
      "[456]\tvalid_0's multi_logloss: 0.628665\n",
      "[457]\tvalid_0's multi_logloss: 0.628632\n",
      "[458]\tvalid_0's multi_logloss: 0.628505\n",
      "[459]\tvalid_0's multi_logloss: 0.628332\n",
      "[460]\tvalid_0's multi_logloss: 0.62819\n",
      "[461]\tvalid_0's multi_logloss: 0.628152\n",
      "[462]\tvalid_0's multi_logloss: 0.62813\n",
      "[463]\tvalid_0's multi_logloss: 0.628111\n",
      "[464]\tvalid_0's multi_logloss: 0.628064\n",
      "[465]\tvalid_0's multi_logloss: 0.628007\n",
      "[466]\tvalid_0's multi_logloss: 0.627879\n",
      "[467]\tvalid_0's multi_logloss: 0.627831\n",
      "[468]\tvalid_0's multi_logloss: 0.627693\n",
      "[469]\tvalid_0's multi_logloss: 0.627638\n",
      "[470]\tvalid_0's multi_logloss: 0.627661\n",
      "[471]\tvalid_0's multi_logloss: 0.627511\n",
      "[472]\tvalid_0's multi_logloss: 0.627497\n",
      "[473]\tvalid_0's multi_logloss: 0.627248\n",
      "[474]\tvalid_0's multi_logloss: 0.627169\n",
      "[475]\tvalid_0's multi_logloss: 0.626984\n",
      "[476]\tvalid_0's multi_logloss: 0.626903\n",
      "[477]\tvalid_0's multi_logloss: 0.626731\n",
      "[478]\tvalid_0's multi_logloss: 0.62677\n",
      "[479]\tvalid_0's multi_logloss: 0.626714\n",
      "[480]\tvalid_0's multi_logloss: 0.626657\n",
      "[481]\tvalid_0's multi_logloss: 0.62664\n",
      "[482]\tvalid_0's multi_logloss: 0.626422\n",
      "[483]\tvalid_0's multi_logloss: 0.6263\n",
      "[484]\tvalid_0's multi_logloss: 0.626186\n",
      "[485]\tvalid_0's multi_logloss: 0.626039\n",
      "[486]\tvalid_0's multi_logloss: 0.626132\n",
      "[487]\tvalid_0's multi_logloss: 0.626077\n",
      "[488]\tvalid_0's multi_logloss: 0.626044\n",
      "[489]\tvalid_0's multi_logloss: 0.625905\n",
      "[490]\tvalid_0's multi_logloss: 0.625819\n",
      "[491]\tvalid_0's multi_logloss: 0.62584\n",
      "[492]\tvalid_0's multi_logloss: 0.625724\n",
      "[493]\tvalid_0's multi_logloss: 0.625828\n",
      "[494]\tvalid_0's multi_logloss: 0.625777\n",
      "[495]\tvalid_0's multi_logloss: 0.625655\n",
      "[496]\tvalid_0's multi_logloss: 0.625483\n",
      "[497]\tvalid_0's multi_logloss: 0.625444\n",
      "[498]\tvalid_0's multi_logloss: 0.625418\n",
      "[499]\tvalid_0's multi_logloss: 0.625375\n",
      "[500]\tvalid_0's multi_logloss: 0.625362\n",
      "[501]\tvalid_0's multi_logloss: 0.625245\n",
      "[502]\tvalid_0's multi_logloss: 0.625188\n",
      "[503]\tvalid_0's multi_logloss: 0.625052\n",
      "[504]\tvalid_0's multi_logloss: 0.624988\n",
      "[505]\tvalid_0's multi_logloss: 0.625037\n",
      "[506]\tvalid_0's multi_logloss: 0.624921\n",
      "[507]\tvalid_0's multi_logloss: 0.624972\n",
      "[508]\tvalid_0's multi_logloss: 0.624756\n",
      "[509]\tvalid_0's multi_logloss: 0.624783\n",
      "[510]\tvalid_0's multi_logloss: 0.624729\n",
      "[511]\tvalid_0's multi_logloss: 0.624776\n",
      "[512]\tvalid_0's multi_logloss: 0.624602\n",
      "[513]\tvalid_0's multi_logloss: 0.624596\n",
      "[514]\tvalid_0's multi_logloss: 0.624533\n",
      "[515]\tvalid_0's multi_logloss: 0.624554\n",
      "[516]\tvalid_0's multi_logloss: 0.624425\n",
      "[517]\tvalid_0's multi_logloss: 0.624332\n",
      "[518]\tvalid_0's multi_logloss: 0.624255\n",
      "[519]\tvalid_0's multi_logloss: 0.624167\n",
      "[520]\tvalid_0's multi_logloss: 0.624222\n",
      "[521]\tvalid_0's multi_logloss: 0.62408\n",
      "[522]\tvalid_0's multi_logloss: 0.624038\n",
      "[523]\tvalid_0's multi_logloss: 0.623996\n",
      "[524]\tvalid_0's multi_logloss: 0.623927\n",
      "[525]\tvalid_0's multi_logloss: 0.623954\n",
      "[526]\tvalid_0's multi_logloss: 0.623937\n",
      "[527]\tvalid_0's multi_logloss: 0.62391\n",
      "[528]\tvalid_0's multi_logloss: 0.623872\n",
      "[529]\tvalid_0's multi_logloss: 0.623915\n",
      "[530]\tvalid_0's multi_logloss: 0.623951\n",
      "[531]\tvalid_0's multi_logloss: 0.623953\n",
      "[532]\tvalid_0's multi_logloss: 0.623942\n",
      "[533]\tvalid_0's multi_logloss: 0.623827\n",
      "[534]\tvalid_0's multi_logloss: 0.623693\n",
      "[535]\tvalid_0's multi_logloss: 0.623773\n",
      "[536]\tvalid_0's multi_logloss: 0.623768\n",
      "[537]\tvalid_0's multi_logloss: 0.623798\n",
      "[538]\tvalid_0's multi_logloss: 0.623801\n",
      "[539]\tvalid_0's multi_logloss: 0.62386\n",
      "[540]\tvalid_0's multi_logloss: 0.623782\n",
      "[541]\tvalid_0's multi_logloss: 0.623732\n",
      "[542]\tvalid_0's multi_logloss: 0.623713\n",
      "[543]\tvalid_0's multi_logloss: 0.623679\n",
      "[544]\tvalid_0's multi_logloss: 0.623798\n",
      "[545]\tvalid_0's multi_logloss: 0.623834\n",
      "[546]\tvalid_0's multi_logloss: 0.623744\n",
      "[547]\tvalid_0's multi_logloss: 0.623753\n",
      "[548]\tvalid_0's multi_logloss: 0.623671\n",
      "[549]\tvalid_0's multi_logloss: 0.623681\n",
      "[550]\tvalid_0's multi_logloss: 0.623677\n",
      "[551]\tvalid_0's multi_logloss: 0.62382\n",
      "[552]\tvalid_0's multi_logloss: 0.623761\n",
      "[553]\tvalid_0's multi_logloss: 0.623765\n",
      "[554]\tvalid_0's multi_logloss: 0.623793\n",
      "[555]\tvalid_0's multi_logloss: 0.623787\n",
      "[556]\tvalid_0's multi_logloss: 0.623951\n",
      "[557]\tvalid_0's multi_logloss: 0.623948\n",
      "[558]\tvalid_0's multi_logloss: 0.623987\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(X_train,y_train, eval_set = (X_test, y_test), early_stopping_rounds = 10)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "# accuracy_scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "# precision_scores.append (metrics.precision_score(y_test,y_pred, average = \"macro\"))\n",
    "# recall_scores.append(metrics.recall_score(y_test,y_pred, average = \"macro\"))\n",
    "# f1_scores.append (metrics.f1_score(y_test,y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d25841",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b7cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"true\" : list(map(lambda value: {1: 'POS', 0: 'NEU', -1: 'NEG'}.get(value), y_test)),\n",
    "\"pred\" : list(map(lambda value: {1: 'POS', 0: 'NEU', -1: 'NEG'}.get(value), y_pred))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0257bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features[[\"sentiment_lexicon_score_summary\", \"sentiment_lexicon_score_review\"]]\n",
    "y = dataset['response']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9c658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e26decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\"true\" : list(map(lambda value: {1: 'POS', 0: 'NEU', -1: 'NEG'}.get(value), y_test)),\n",
    "\"pred\" : list(map(lambda value: {1: 'POS', 0: 'NEU', -1: 'NEG'}.get(value), y_pred)),\n",
    "\"index\":y_test.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c0ae83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>2886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>2379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>4401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true pred  index\n",
       "27    NEU  POS   1621\n",
       "36    NEU  POS   2646\n",
       "69    NEU  POS   2886\n",
       "71    NEU  POS   1747\n",
       "85    NEU  POS    721\n",
       "...   ...  ...    ...\n",
       "1269  NEU  POS   2389\n",
       "1302  NEU  POS   2379\n",
       "1308  NEU  POS   4122\n",
       "1320  NEU  POS   2992\n",
       "1324  NEU  POS   4401\n",
       "\n",
       "[71 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.apply(lambda row: row[\"true\"]==\"NEU\" and row[\"pred\"]==\"POS\", axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3598a086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': \"I'm a bit leery\",\n",
       " 'reviewText': 'I\\'m a bit leery of this product. I\\'ve been a Norton customer since it first started providing security services. The product detail says 25GB of Online Backup, but I receive a 5GB Online Back Up card via Amazon Vine. Where my skepticism comes in is the product is an annual product like all other Norton products. In addition to this product being comparible to services like DropBox, Box, and SkyDrive, I looked through the TOS and the product paperwork that came in the package for what happens to my back ups provided I do NOT renew this service on an annual basis. Do I lose access to what I\\'ve already backed up? If this is the case, this could be detrimental and I would suffer a loss of my personal files. I currently have a ticket into Norton to see what happens to my files provided I do not renew. I will post their response when I receive an answer, but I am not going to back up anything until I know the answer. One would thing that this would displayed clearly somewhere in the TOS. Now the actual product is 25GB is a a good amount, however, it is still comparable to the other online storage and back up services I mentioned above. With that being said, I already pay Norton in excess of $120 for Cyber Security products and multiple family back ups across devices, do I want to give them another $25 for online storage? You may want to bypass this one, but I will post the response from Norton about the \"shelf-life\" of my back ups as soon as I hear from them.',\n",
       " 'asin': 'B002X8V326',\n",
       " 'brand': 'Symantec',\n",
       " 'sentiment': 'NEU',\n",
       " 'reviewId': 1379,\n",
       " 'response': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1378].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "558e9993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Easy download - good program',\n",
       " 'reviewText': \"Used H&R Block tax software for the first time last year - it was cheaper than what I had been using.Since they didn't constantly bug me to buy it again this year, and it worked well last year, I purchased again.I'm very glad that I'm not getting constant pleas to buy their software.  And, it loaded last year's info just fine!I haven't efiled, yet - but that went well last year & I'm expecting it to go fine this year, too.Update:  E-filing is great  Having the name of tax professionals behind it is comforting  But, downgraded to 3-stars because I had difficulty understanding some tax issues. Had to resort to the H&R block website (which was very good, and has helpful comments).  But still, if links to IRS rules were available for each item I wouldn't have had to search as much.\",\n",
       " 'asin': 'B004A7Y0UK',\n",
       " 'brand': 'H&R Block',\n",
       " 'sentiment': 'NEU',\n",
       " 'reviewId': 1622,\n",
       " 'response': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1621].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
