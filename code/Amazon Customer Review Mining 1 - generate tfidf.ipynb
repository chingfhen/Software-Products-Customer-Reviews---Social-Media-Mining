{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c3268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ecc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22a8c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviewId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is excellent software for those who want ...</td>\n",
       "      <td>If you've been wanting to learn how to create ...</td>\n",
       "      <td>0321719816</td>\n",
       "      <td>Peach Pit Press</td>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Competent introduction to Dreamweaver and web ...</td>\n",
       "      <td>I waited to complete the entire course before ...</td>\n",
       "      <td>0321719816</td>\n",
       "      <td>Peach Pit Press</td>\n",
       "      <td>NEU</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learn Adobe Photoshop Lightroom 3 by Video (Le...</td>\n",
       "      <td>As someone who has just upgraded from Lightroo...</td>\n",
       "      <td>0321700945</td>\n",
       "      <td>Peach Pit Press</td>\n",
       "      <td>POS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For Highly Motivated and Patient People</td>\n",
       "      <td>There are over 100 video lessons here. Most us...</td>\n",
       "      <td>0321700945</td>\n",
       "      <td>Peach Pit Press</td>\n",
       "      <td>NEU</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good Intro to Flash CS5</td>\n",
       "      <td>This was the first Learn by Video series cours...</td>\n",
       "      <td>0321719824</td>\n",
       "      <td>Peach Pit Press</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  This is excellent software for those who want ...   \n",
       "1  Competent introduction to Dreamweaver and web ...   \n",
       "2  Learn Adobe Photoshop Lightroom 3 by Video (Le...   \n",
       "3            For Highly Motivated and Patient People   \n",
       "4                            Good Intro to Flash CS5   \n",
       "\n",
       "                                          reviewText        asin  \\\n",
       "0  If you've been wanting to learn how to create ...  0321719816   \n",
       "1  I waited to complete the entire course before ...  0321719816   \n",
       "2  As someone who has just upgraded from Lightroo...  0321700945   \n",
       "3  There are over 100 video lessons here. Most us...  0321700945   \n",
       "4  This was the first Learn by Video series cours...  0321719824   \n",
       "\n",
       "             brand sentiment  reviewId  \n",
       "0  Peach Pit Press       POS         1  \n",
       "1  Peach Pit Press       NEU         2  \n",
       "2  Peach Pit Press       POS         3  \n",
       "3  Peach Pit Press       NEU         4  \n",
       "4  Peach Pit Press       POS         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41277b80",
   "metadata": {},
   "source": [
    "## cleaning: \n",
    "- merge summary and reviews\n",
    "- remove all non alphabetical characters\n",
    "- remove stopwords\n",
    "- lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc29b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lemmatize+remove_stopwords+remove_nonalpha_char\n",
    "\"\"\"\n",
    "def clean_text(text):\n",
    "    return lemmatize(remove_stopwords(remove_nonalpha_char(str(text)))).lower()\n",
    "stopwords_dict = {v:i for i,v in enumerate(stopwords.words('english'))}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def remove_nonalpha_char(text):\n",
    "    return re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "def remove_stopwords(text):\n",
    "    def is_stopword(word):\n",
    "        return stopwords_dict.get(word.lower()) is not None\n",
    "    return \" \".join([word for word in text.split() if not is_stopword(word)])\n",
    "def lemmatize(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b28914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"clean_reviews\"] = (dataset['summary']+\" \"+dataset.reviewText).map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af816311",
   "metadata": {},
   "source": [
    "### generate tfidf features for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebed3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset[\"clean_reviews\"])\n",
    "# tfidf_features = pd.DataFrame(tfidf_matrix.toarray(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c11b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf.npy\"\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "361a3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CS4022 - Social Media Mining\\Assignments\\Assignment 2 - Customer Review Mining Project\\data\\tfidf_names.npy\"\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a5913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b37c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5638ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957659423303254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sprasity\n",
    "(tfidf_features.to_numpy() == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe48117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
